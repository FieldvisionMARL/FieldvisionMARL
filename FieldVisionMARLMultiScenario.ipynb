{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxaRXrKoa68F",
        "outputId": "d38efdd5-000c-41eb-ab49-7641fb218c45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "if device == \"cuda\":\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "from fieldvision_complete import (\n",
        "    make_multi_drone_env,\n",
        "    get_difficulty_config,\n",
        "    MAPPOWrapper,\n",
        ")\n",
        "\n",
        "import fieldvision_complete\n",
        "TrainingConfig = fieldvision_complete.TrainingConfig\n",
        "Trainer = fieldvision_complete.Trainer\n",
        "\n",
        "from evaluation_pipeline import (\n",
        "    evaluate_all_baselines,\n",
        "    get_all_policies,\n",
        "    evaluate_policy,\n",
        "    MetricCollector,\n",
        "    MARLResultsAdapter,\n",
        "    create_summary_table,\n",
        "    create_latex_table,\n",
        "    generate_comprehensive_figures,\n",
        "    print_results_summary,\n",
        "    save_comprehensive_checkpoint,\n",
        "    aggregate_marl_results,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FF6N0X7ubPz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SCENARIOS = [\"streaming_hard\", \"rural_field\", \"variable_terrain\", \"network_aware\"]\n",
        "TOTAL_TIMESTEPS = 200_000  # Reduce for faster testing (50_000 for quick test)\n",
        "N_SEEDS = 3               # Number of random seeds per algorithm\n",
        "N_EVAL_EPISODES = 10      # Episodes per evaluation\n",
        "N_BASELINE_EPISODES = 30  # Episodes for baseline evaluation\n",
        "OUTPUT_DIR = \"ijcnn_results\"\n",
        "# ===========================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"EXPERIMENT CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Scenarios: {SCENARIOS}\")\n",
        "print(f\"Training timesteps: {TOTAL_TIMESTEPS:,}\")\n",
        "print(f\"Seeds per algorithm: {N_SEEDS}\")\n",
        "print(f\"Eval episodes per seed: {N_EVAL_EPISODES}\")\n",
        "print(f\"Baseline episodes: {N_BASELINE_EPISODES}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxHaSC0UbZms",
        "outputId": "afeaafa1-b87d-4f46-dc4e-eb5cdf2e8be8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "EXPERIMENT CONFIGURATION\n",
            "============================================================\n",
            "Scenarios: ['streaming_hard', 'rural_field', 'variable_terrain', 'network_aware']\n",
            "Training timesteps: 200,000\n",
            "Seeds per algorithm: 3\n",
            "Eval episodes per seed: 10\n",
            "Baseline episodes: 30\n",
            "Output directory: ijcnn_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QFBzY3YgbCYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PHASE 1: BASELINE EVALUATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "all_baseline_results = {}\n",
        "\n",
        "for scenario in SCENARIOS:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Evaluating baselines on: {scenario.upper()}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    baseline_results = evaluate_all_baselines(\n",
        "        difficulty=scenario,\n",
        "        n_episodes=N_BASELINE_EPISODES,\n",
        "        seed=42,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    all_baseline_results[scenario] = baseline_results\n",
        "\n",
        "    # Print summary for this scenario\n",
        "    print(f\"\\n--- {scenario} Baseline Summary ---\")\n",
        "    for name, collector in baseline_results.items():\n",
        "        s = collector.summary()\n",
        "        print(f\"{name:20s}: Reward={s['reward_mean']:7.1f}±{s['reward_std']:5.1f}  \"\n",
        "              f\"Comp={s['completion']:5.1f}%  OnTime={s['on_time_rate']:5.1f}%  \"\n",
        "              f\"Battery={s.get('battery_used_pct', 0):5.1f}%\")\n",
        "\n",
        "print(\"\\n✓ Baseline evaluation complete\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ3eiQ9pbd_2",
        "outputId": "2bc8b42b-4c5d-44ed-9766-fae6fcb70819"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PHASE 1: BASELINE EVALUATION\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Evaluating baselines on: STREAMING_HARD\n",
            "============================================================\n",
            "============================================================\n",
            "BASELINE EVALUATION - streaming_hard\n",
            "Episodes: 30, Seed: 42\n",
            "============================================================\n",
            "\n",
            "Evaluating Local-Only...\n",
            "  Reward: -6693.2 ± 0.0\n",
            "  Actions: L=100% E=0% C=0%\n",
            "\n",
            "Evaluating Edge-Only...\n",
            "  Reward: 209.3 ± 151.4\n",
            "  Actions: L=0% E=100% C=0%\n",
            "\n",
            "Evaluating Cloud-Only...\n",
            "  Reward: 2.1 ± 132.5\n",
            "  Actions: L=0% E=0% C=100%\n",
            "\n",
            "Evaluating Round-Robin...\n",
            "  Reward: -170.3 ± 93.8\n",
            "  Actions: L=34% E=33% C=33%\n",
            "\n",
            "Evaluating Random...\n",
            "  Reward: 121.8 ± 111.9\n",
            "  Actions: L=34% E=33% C=33%\n",
            "\n",
            "Evaluating Multi-Metric...\n",
            "  Reward: 305.5 ± 109.4\n",
            "  Actions: L=47% E=53% C=0%\n",
            "\n",
            "Evaluating Multi-Metric-BW...\n",
            "  Reward: 245.0 ± 133.9\n",
            "  Actions: L=22% E=78% C=0%\n",
            "\n",
            "Evaluating Multi-Metric-Urgent...\n",
            "  Reward: 295.7 ± 106.3\n",
            "  Actions: L=49% E=49% C=2%\n",
            "\n",
            "Evaluating Latency-Greedy...\n",
            "  Reward: 2.1 ± 132.5\n",
            "  Actions: L=0% E=0% C=100%\n",
            "\n",
            "--- streaming_hard Baseline Summary ---\n",
            "Local-Only          : Reward=-6693.2±  0.0  Comp= 83.3%  OnTime= 83.3%  Battery= 92.0%\n",
            "Edge-Only           : Reward=  209.3±151.4  Comp= 72.6%  OnTime= 72.6%  Battery=  0.0%\n",
            "Cloud-Only          : Reward=    2.1±132.5  Comp= 72.6%  OnTime= 72.6%  Battery=  0.0%\n",
            "Round-Robin         : Reward= -170.3± 93.8  Comp= 84.2%  OnTime= 84.2%  Battery= 48.3%\n",
            "Random              : Reward=  121.8±111.9  Comp= 82.6%  OnTime= 82.6%  Battery= 42.9%\n",
            "Multi-Metric        : Reward=  305.5±109.4  Comp= 84.8%  OnTime= 84.8%  Battery= 34.1%\n",
            "Multi-Metric-BW     : Reward=  245.0±133.9  Comp= 78.3%  OnTime= 78.3%  Battery= 17.0%\n",
            "Multi-Metric-Urgent : Reward=  295.7±106.3  Comp= 85.8%  OnTime= 85.8%  Battery= 37.2%\n",
            "Latency-Greedy      : Reward=    2.1±132.5  Comp= 72.6%  OnTime= 72.6%  Battery=  0.0%\n",
            "\n",
            "============================================================\n",
            "Evaluating baselines on: RURAL_FIELD\n",
            "============================================================\n",
            "============================================================\n",
            "BASELINE EVALUATION - rural_field\n",
            "Episodes: 30, Seed: 42\n",
            "============================================================\n",
            "\n",
            "Evaluating Local-Only...\n",
            "  Reward: -5057.3 ± 0.0\n",
            "  Actions: L=100% E=0% C=0%\n",
            "\n",
            "Evaluating Edge-Only...\n",
            "  Reward: 234.8 ± 99.4\n",
            "  Actions: L=0% E=100% C=0%\n",
            "\n",
            "Evaluating Cloud-Only...\n",
            "  Reward: 53.3 ± 88.9\n",
            "  Actions: L=0% E=0% C=100%\n",
            "\n",
            "Evaluating Round-Robin...\n",
            "  Reward: 141.8 ± 77.8\n",
            "  Actions: L=33% E=33% C=33%\n",
            "\n",
            "Evaluating Random...\n",
            "  Reward: 143.4 ± 70.7\n",
            "  Actions: L=34% E=33% C=33%\n",
            "\n",
            "Evaluating Multi-Metric...\n",
            "  Reward: 329.4 ± 87.4\n",
            "  Actions: L=48% E=52% C=0%\n",
            "\n",
            "Evaluating Multi-Metric-BW...\n",
            "  Reward: 249.0 ± 89.9\n",
            "  Actions: L=21% E=79% C=0%\n",
            "\n",
            "Evaluating Multi-Metric-Urgent...\n",
            "  Reward: 321.0 ± 82.4\n",
            "  Actions: L=49% E=49% C=2%\n",
            "\n",
            "Evaluating Latency-Greedy...\n",
            "  Reward: 53.3 ± 88.9\n",
            "  Actions: L=0% E=0% C=100%\n",
            "\n",
            "--- rural_field Baseline Summary ---\n",
            "Local-Only          : Reward=-5057.3±  0.0  Comp= 95.0%  OnTime= 95.0%  Battery= 80.0%\n",
            "Edge-Only           : Reward=  234.8± 99.4  Comp= 81.4%  OnTime= 81.4%  Battery=  0.0%\n",
            "Cloud-Only          : Reward=   53.3± 88.9  Comp= 81.4%  OnTime= 81.4%  Battery=  0.0%\n",
            "Round-Robin         : Reward=  141.8± 77.8  Comp= 87.3%  OnTime= 87.3%  Battery= 30.2%\n",
            "Random              : Reward=  143.4± 70.7  Comp= 88.6%  OnTime= 88.6%  Battery= 32.0%\n",
            "Multi-Metric        : Reward=  329.4± 87.4  Comp= 89.2%  OnTime= 89.2%  Battery= 25.1%\n",
            "Multi-Metric-BW     : Reward=  249.0± 89.9  Comp= 84.4%  OnTime= 84.4%  Battery= 12.1%\n",
            "Multi-Metric-Urgent : Reward=  321.0± 82.4  Comp= 89.4%  OnTime= 89.4%  Battery= 25.5%\n",
            "Latency-Greedy      : Reward=   53.3± 88.9  Comp= 81.4%  OnTime= 81.4%  Battery=  0.0%\n",
            "\n",
            "============================================================\n",
            "Evaluating baselines on: VARIABLE_TERRAIN\n",
            "============================================================\n",
            "============================================================\n",
            "BASELINE EVALUATION - variable_terrain\n",
            "Episodes: 30, Seed: 42\n",
            "============================================================\n",
            "\n",
            "Evaluating Local-Only...\n",
            "  Reward: -6467.2 ± 0.0\n",
            "  Actions: L=100% E=0% C=0%\n",
            "\n",
            "Evaluating Edge-Only...\n",
            "  Reward: -230.3 ± 79.3\n",
            "  Actions: L=0% E=100% C=0%\n",
            "\n",
            "Evaluating Cloud-Only...\n",
            "  Reward: -377.3 ± 66.4\n",
            "  Actions: L=0% E=0% C=100%\n",
            "\n",
            "Evaluating Round-Robin...\n",
            "  Reward: -327.4 ± 62.8\n",
            "  Actions: L=33% E=33% C=33%\n",
            "\n",
            "Evaluating Random...\n",
            "  Reward: -175.5 ± 49.3\n",
            "  Actions: L=34% E=33% C=33%\n",
            "\n",
            "Evaluating Multi-Metric...\n",
            "  Reward: 55.5 ± 72.1\n",
            "  Actions: L=51% E=49% C=0%\n",
            "\n",
            "Evaluating Multi-Metric-BW...\n",
            "  Reward: -66.8 ± 53.6\n",
            "  Actions: L=35% E=65% C=0%\n",
            "\n",
            "Evaluating Multi-Metric-Urgent...\n",
            "  Reward: 48.0 ± 68.3\n",
            "  Actions: L=52% E=46% C=3%\n",
            "\n",
            "Evaluating Latency-Greedy...\n",
            "  Reward: -377.3 ± 66.4\n",
            "  Actions: L=0% E=0% C=100%\n",
            "\n",
            "--- variable_terrain Baseline Summary ---\n",
            "Local-Only          : Reward=-6467.2±  0.0  Comp= 87.5%  OnTime= 87.5%  Battery= 86.0%\n",
            "Edge-Only           : Reward= -230.3± 79.3  Comp= 22.5%  OnTime= 22.5%  Battery=  0.0%\n",
            "Cloud-Only          : Reward= -377.3± 66.4  Comp= 22.5%  OnTime= 22.5%  Battery=  0.0%\n",
            "Round-Robin         : Reward= -327.4± 62.8  Comp= 58.9%  OnTime= 58.9%  Battery= 47.9%\n",
            "Random              : Reward= -175.5± 49.3  Comp= 48.0%  OnTime= 48.0%  Battery= 36.2%\n",
            "Multi-Metric        : Reward=   55.5± 72.1  Comp= 59.6%  OnTime= 59.6%  Battery= 39.8%\n",
            "Multi-Metric-BW     : Reward=  -66.8± 53.6  Comp= 49.2%  OnTime= 49.2%  Battery= 29.6%\n",
            "Multi-Metric-Urgent : Reward=   48.0± 68.3  Comp= 60.1%  OnTime= 60.1%  Battery= 40.4%\n",
            "Latency-Greedy      : Reward= -377.3± 66.4  Comp= 22.5%  OnTime= 22.5%  Battery=  0.0%\n",
            "\n",
            "============================================================\n",
            "Evaluating baselines on: NETWORK_AWARE\n",
            "============================================================\n",
            "============================================================\n",
            "BASELINE EVALUATION - network_aware\n",
            "Episodes: 30, Seed: 42\n",
            "============================================================\n",
            "\n",
            "Evaluating Local-Only...\n",
            "  Reward: -6693.2 ± 0.0\n",
            "  Actions: L=100% E=0% C=0%\n",
            "\n",
            "Evaluating Edge-Only...\n",
            "  Reward: -235.4 ± 71.6\n",
            "  Actions: L=0% E=100% C=0%\n",
            "\n",
            "Evaluating Cloud-Only...\n",
            "  Reward: -381.4 ± 60.5\n",
            "  Actions: L=0% E=0% C=100%\n",
            "\n",
            "Evaluating Round-Robin...\n",
            "  Reward: -413.3 ± 53.7\n",
            "  Actions: L=34% E=33% C=33%\n",
            "\n",
            "Evaluating Random...\n",
            "  Reward: -184.5 ± 71.2\n",
            "  Actions: L=34% E=33% C=33%\n",
            "\n",
            "Evaluating Multi-Metric...\n",
            "  Reward: 5.7 ± 61.4\n",
            "  Actions: L=51% E=48% C=0%\n",
            "\n",
            "Evaluating Multi-Metric-BW...\n",
            "  Reward: -84.7 ± 58.9\n",
            "  Actions: L=37% E=63% C=0%\n",
            "\n",
            "Evaluating Multi-Metric-Urgent...\n",
            "  Reward: 1.0 ± 58.0\n",
            "  Actions: L=52% E=46% C=2%\n",
            "\n",
            "Evaluating Latency-Greedy...\n",
            "  Reward: -381.4 ± 60.5\n",
            "  Actions: L=0% E=0% C=100%\n",
            "\n",
            "--- network_aware Baseline Summary ---\n",
            "Local-Only          : Reward=-6693.2±  0.0  Comp= 83.3%  OnTime= 83.3%  Battery= 92.0%\n",
            "Edge-Only           : Reward= -235.4± 71.6  Comp= 21.7%  OnTime= 21.7%  Battery=  0.0%\n",
            "Cloud-Only          : Reward= -381.4± 60.5  Comp= 21.7%  OnTime= 21.7%  Battery=  0.0%\n",
            "Round-Robin         : Reward= -413.3± 53.7  Comp= 55.3%  OnTime= 55.3%  Battery= 51.1%\n",
            "Random              : Reward= -184.5± 71.2  Comp= 50.3%  OnTime= 50.3%  Battery= 45.3%\n",
            "Multi-Metric        : Reward=    5.7± 61.4  Comp= 59.3%  OnTime= 59.3%  Battery= 47.5%\n",
            "Multi-Metric-BW     : Reward=  -84.7± 58.9  Comp= 48.4%  OnTime= 48.4%  Battery= 36.8%\n",
            "Multi-Metric-Urgent : Reward=    1.0± 58.0  Comp= 59.9%  OnTime= 59.9%  Battery= 48.1%\n",
            "Latency-Greedy      : Reward= -381.4± 60.5  Comp= 21.7%  OnTime= 21.7%  Battery=  0.0%\n",
            "\n",
            "✓ Baseline evaluation complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e7OLawFCbiHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PHASE 2: MARL TRAINING\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "all_marl_results = {}\n",
        "all_trainers = {}  # Store for potential cross-evaluation\n",
        "\n",
        "algorithms = [\"mappo\"]\n",
        "\n",
        "for scenario in SCENARIOS:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TRAINING ON: {scenario.upper()}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    env_config = get_difficulty_config(scenario)\n",
        "    config = TrainingConfig(\n",
        "        total_timesteps=TOTAL_TIMESTEPS,\n",
        "        max_steps_per_episode=env_config.get(\"max_steps\", 100)\n",
        "    )\n",
        "\n",
        "    def make_env_with_seed(seed=None):\n",
        "        if seed is None:\n",
        "            seed = np.random.randint(0, 100000)\n",
        "        return make_multi_drone_env(seed=seed, **env_config)\n",
        "\n",
        "    scenario_results = {}\n",
        "    scenario_trainers = {}\n",
        "\n",
        "    for alg in algorithms:\n",
        "        print(f\"\\n--- {alg} ---\")\n",
        "\n",
        "        # Collect results across seeds\n",
        "        all_rewards = []\n",
        "        all_completions = []\n",
        "        all_deadline_misses = []\n",
        "        all_transfer_failures = []\n",
        "        all_on_time_rates = []\n",
        "        all_tasks_on_time = []\n",
        "        all_tasks_late = []\n",
        "        all_latencies = []\n",
        "        all_battery_used = []\n",
        "        all_local_pct = []\n",
        "        all_edge_pct = []\n",
        "        all_cloud_pct = []\n",
        "\n",
        "        for seed in range(N_SEEDS):\n",
        "            print(f\"  Seed {seed + 1}/{N_SEEDS}...\", end=\" \", flush=True)\n",
        "            torch.manual_seed(seed)\n",
        "            np.random.seed(seed)\n",
        "\n",
        "            log_dir = f\"{OUTPUT_DIR}/models/{scenario}/{alg}/seed_{seed}\"\n",
        "            trainer = Trainer(alg, config, make_env_with_seed, log_dir)\n",
        "            trainer.train()\n",
        "\n",
        "            # Evaluate\n",
        "            stats = trainer.evaluate(n_episodes=N_EVAL_EPISODES, base_seed=2000 + seed * 100)\n",
        "\n",
        "            # Collect per-episode data\n",
        "            all_rewards.extend(stats['rewards'])\n",
        "            all_completions.extend(stats.get('completions', [stats['completion']]))\n",
        "            all_deadline_misses.extend(stats.get('deadline_misses_list', []))\n",
        "            all_transfer_failures.extend(stats.get('transfer_failures_list', []))\n",
        "            all_on_time_rates.extend(stats.get('on_time_rates_list', []))\n",
        "            all_tasks_on_time.extend(stats.get('tasks_on_time_list', []))\n",
        "            all_tasks_late.extend(stats.get('tasks_late_list', []))\n",
        "            all_latencies.extend(stats.get('ep_mean_latencies', []))\n",
        "            all_battery_used.append(stats.get('battery_used_pct', 0))\n",
        "            all_local_pct.append(stats['local_pct'])\n",
        "            all_edge_pct.append(stats['edge_pct'])\n",
        "            all_cloud_pct.append(stats['cloud_pct'])\n",
        "\n",
        "            scenario_trainers[(alg, seed)] = trainer\n",
        "            print(f\"reward={stats['reward_mean']:.1f}\")\n",
        "\n",
        "        # Aggregate\n",
        "        scenario_results[alg] = {\n",
        "            'reward_mean': np.mean(all_rewards),\n",
        "            'reward_std': np.std(all_rewards),\n",
        "            'rewards': all_rewards,\n",
        "            'completion': np.mean(all_completions),\n",
        "            'completions': all_completions,\n",
        "            'deadline_misses': np.mean(all_deadline_misses) if all_deadline_misses else 0,\n",
        "            'deadline_misses_list': all_deadline_misses,\n",
        "            'transfer_failures': np.mean(all_transfer_failures) if all_transfer_failures else 0,\n",
        "            'transfer_failures_list': all_transfer_failures,\n",
        "            'on_time_rate': np.mean(all_on_time_rates) if all_on_time_rates else 100,\n",
        "            'on_time_rates_list': all_on_time_rates,\n",
        "            'tasks_on_time_list': all_tasks_on_time,\n",
        "            'tasks_late_list': all_tasks_late,\n",
        "            'avg_latency': np.mean(all_latencies) if all_latencies else 0,\n",
        "            'latency_std': np.std(all_latencies) if all_latencies else 0,\n",
        "            'ep_mean_latencies': all_latencies,\n",
        "            'battery_used_pct': np.mean(all_battery_used),\n",
        "            'local_pct': np.mean(all_local_pct),\n",
        "            'edge_pct': np.mean(all_edge_pct),\n",
        "            'cloud_pct': np.mean(all_cloud_pct),\n",
        "        }\n",
        "\n",
        "        print(f\"  {alg}: {scenario_results[alg]['reward_mean']:.1f} ± {scenario_results[alg]['reward_std']:.1f}\")\n",
        "\n",
        "    all_marl_results[scenario] = scenario_results\n",
        "    all_trainers[scenario] = scenario_trainers\n",
        "\n",
        "print(\"\\n✓ MARL training complete\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym8Y0saAbiaz",
        "outputId": "27de2ffc-f570-4e47-ad5e-234de62d3098"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PHASE 2: MARL TRAINING\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TRAINING ON: STREAMING_HARD\n",
            "======================================================================\n",
            "\n",
            "--- mappo ---\n",
            "  Seed 1/3... Update 10/195 | Steps: 10,240 | Reward: 195.46 | A_Loss: 0.0181 | C_Loss: 356.2749 | Ent: 0.396\n",
            "Update 20/195 | Steps: 20,480 | Reward: 294.93 | A_Loss: -0.0612 | C_Loss: 247.2916 | Ent: 0.181\n",
            "Update 30/195 | Steps: 30,720 | Reward: 288.42 | A_Loss: -0.0794 | C_Loss: 327.2029 | Ent: 0.129\n",
            "Update 40/195 | Steps: 40,960 | Reward: 291.55 | A_Loss: -0.0754 | C_Loss: 307.2035 | Ent: 0.090\n",
            "Update 50/195 | Steps: 51,200 | Reward: 303.48 | A_Loss: -0.0960 | C_Loss: 341.1252 | Ent: 0.053\n",
            "Update 60/195 | Steps: 61,440 | Reward: 322.08 | A_Loss: -0.0356 | C_Loss: 252.4222 | Ent: 0.023\n",
            "Update 70/195 | Steps: 71,680 | Reward: 311.23 | A_Loss: -0.0269 | C_Loss: 335.0631 | Ent: 0.014\n",
            "Update 80/195 | Steps: 81,920 | Reward: 322.60 | A_Loss: -0.0576 | C_Loss: 377.2133 | Ent: 0.006\n",
            "Update 90/195 | Steps: 92,160 | Reward: 310.94 | A_Loss: -0.1086 | C_Loss: 267.9602 | Ent: 0.009\n",
            "Update 100/195 | Steps: 102,400 | Reward: 292.27 | A_Loss: -0.0713 | C_Loss: 281.8323 | Ent: 0.010\n",
            "Update 110/195 | Steps: 112,640 | Reward: 297.06 | A_Loss: -0.0871 | C_Loss: 313.2660 | Ent: 0.013\n",
            "Update 120/195 | Steps: 122,880 | Reward: 297.30 | A_Loss: -0.0201 | C_Loss: 326.4000 | Ent: 0.003\n",
            "Update 130/195 | Steps: 133,120 | Reward: 301.44 | A_Loss: -0.0320 | C_Loss: 338.1816 | Ent: 0.002\n",
            "Update 140/195 | Steps: 143,360 | Reward: 315.93 | A_Loss: -0.0198 | C_Loss: 317.7401 | Ent: 0.008\n",
            "Update 150/195 | Steps: 153,600 | Reward: 319.71 | A_Loss: -0.0399 | C_Loss: 339.8028 | Ent: 0.061\n",
            "Update 160/195 | Steps: 163,840 | Reward: 318.63 | A_Loss: -0.0392 | C_Loss: 232.5067 | Ent: 0.042\n",
            "Update 170/195 | Steps: 174,080 | Reward: 305.39 | A_Loss: -0.0696 | C_Loss: 286.8099 | Ent: 0.074\n",
            "Update 180/195 | Steps: 184,320 | Reward: 303.26 | A_Loss: -0.0504 | C_Loss: 292.9776 | Ent: 0.013\n",
            "Update 190/195 | Steps: 194,560 | Reward: 304.05 | A_Loss: -0.0950 | C_Loss: 301.0859 | Ent: 0.005\n",
            "    Actions (when tasks): L=50% E=50% C=0%\n",
            "    (484 decisions with tasks / 2032 total)\n",
            "      MPD_0: L=100% E=0% C=0% (120 decisions)\n",
            "      MPD_1: L=100% E=0% C=0% (120 decisions)\n",
            "      LPD_0: L=0% E=99% C=1% (123 decisions)\n",
            "      LPD_1: L=0% E=100% C=0% (121 decisions)\n",
            "reward=393.3\n",
            "  Seed 2/3... Update 10/195 | Steps: 10,240 | Reward: 180.67 | A_Loss: 0.1094 | C_Loss: 403.0848 | Ent: 0.491\n",
            "Update 20/195 | Steps: 20,480 | Reward: 295.38 | A_Loss: -0.0491 | C_Loss: 306.6984 | Ent: 0.116\n",
            "Update 30/195 | Steps: 30,720 | Reward: 287.60 | A_Loss: -0.0826 | C_Loss: 330.2635 | Ent: 0.031\n",
            "Update 40/195 | Steps: 40,960 | Reward: 296.65 | A_Loss: -0.0760 | C_Loss: 308.4233 | Ent: 0.025\n",
            "Update 50/195 | Steps: 51,200 | Reward: 305.01 | A_Loss: -0.0953 | C_Loss: 331.9890 | Ent: 0.067\n",
            "Update 60/195 | Steps: 61,440 | Reward: 320.20 | A_Loss: -0.0251 | C_Loss: 244.2285 | Ent: 0.081\n",
            "Update 70/195 | Steps: 71,680 | Reward: 310.79 | A_Loss: -0.0522 | C_Loss: 329.7283 | Ent: 0.044\n",
            "Update 80/195 | Steps: 81,920 | Reward: 324.09 | A_Loss: -0.0592 | C_Loss: 342.0236 | Ent: 0.032\n",
            "Update 90/195 | Steps: 92,160 | Reward: 311.07 | A_Loss: -0.1106 | C_Loss: 267.3598 | Ent: 0.048\n",
            "Update 100/195 | Steps: 102,400 | Reward: 290.22 | A_Loss: -0.0680 | C_Loss: 278.2356 | Ent: 0.032\n",
            "Update 110/195 | Steps: 112,640 | Reward: 297.97 | A_Loss: -0.0886 | C_Loss: 297.5873 | Ent: 0.010\n",
            "Update 120/195 | Steps: 122,880 | Reward: 296.18 | A_Loss: -0.0238 | C_Loss: 324.5574 | Ent: 0.006\n",
            "Update 130/195 | Steps: 133,120 | Reward: 301.32 | A_Loss: -0.0311 | C_Loss: 335.0613 | Ent: 0.011\n",
            "Update 140/195 | Steps: 143,360 | Reward: 315.53 | A_Loss: -0.0214 | C_Loss: 317.8656 | Ent: 0.008\n",
            "Update 150/195 | Steps: 153,600 | Reward: 320.90 | A_Loss: -0.0322 | C_Loss: 341.9318 | Ent: 0.008\n",
            "Update 160/195 | Steps: 163,840 | Reward: 320.00 | A_Loss: -0.0389 | C_Loss: 232.1468 | Ent: 0.012\n",
            "Update 170/195 | Steps: 174,080 | Reward: 305.91 | A_Loss: -0.0601 | C_Loss: 290.3056 | Ent: 0.002\n",
            "Update 180/195 | Steps: 184,320 | Reward: 303.57 | A_Loss: -0.0397 | C_Loss: 291.0694 | Ent: 0.001\n",
            "Update 190/195 | Steps: 194,560 | Reward: 303.75 | A_Loss: -0.0774 | C_Loss: 303.9967 | Ent: 0.002\n",
            "    Actions (when tasks): L=49% E=51% C=0%\n",
            "    (488 decisions with tasks / 2020 total)\n",
            "      MPD_0: L=100% E=0% C=0% (120 decisions)\n",
            "      MPD_1: L=100% E=0% C=0% (120 decisions)\n",
            "      LPD_0: L=0% E=100% C=0% (125 decisions)\n",
            "      LPD_1: L=0% E=100% C=0% (123 decisions)\n",
            "reward=240.6\n",
            "  Seed 3/3... Update 10/195 | Steps: 10,240 | Reward: 200.68 | A_Loss: 0.0444 | C_Loss: 387.3021 | Ent: 0.375\n",
            "Update 20/195 | Steps: 20,480 | Reward: 298.23 | A_Loss: -0.0630 | C_Loss: 299.1228 | Ent: 0.057\n",
            "Update 30/195 | Steps: 30,720 | Reward: 292.57 | A_Loss: -0.0740 | C_Loss: 339.8898 | Ent: 0.037\n",
            "Update 40/195 | Steps: 40,960 | Reward: 297.62 | A_Loss: -0.0761 | C_Loss: 308.3481 | Ent: 0.024\n",
            "Update 50/195 | Steps: 51,200 | Reward: 305.73 | A_Loss: -0.0952 | C_Loss: 343.1568 | Ent: 0.026\n",
            "Update 60/195 | Steps: 61,440 | Reward: 323.60 | A_Loss: -0.0462 | C_Loss: 246.1283 | Ent: 0.013\n",
            "Update 70/195 | Steps: 71,680 | Reward: 312.60 | A_Loss: -0.0593 | C_Loss: 332.0148 | Ent: 0.005\n",
            "Update 80/195 | Steps: 81,920 | Reward: 326.42 | A_Loss: -0.0667 | C_Loss: 340.6857 | Ent: 0.005\n",
            "Update 90/195 | Steps: 92,160 | Reward: 312.57 | A_Loss: -0.1162 | C_Loss: 268.7901 | Ent: 0.008\n",
            "Update 100/195 | Steps: 102,400 | Reward: 291.28 | A_Loss: -0.0653 | C_Loss: 278.1903 | Ent: 0.002\n",
            "Update 110/195 | Steps: 112,640 | Reward: 296.83 | A_Loss: -0.0849 | C_Loss: 312.1444 | Ent: 0.001\n",
            "Update 120/195 | Steps: 122,880 | Reward: 297.31 | A_Loss: -0.0084 | C_Loss: 323.9118 | Ent: 0.002\n",
            "Update 130/195 | Steps: 133,120 | Reward: 302.02 | A_Loss: -0.0176 | C_Loss: 334.8159 | Ent: 0.003\n",
            "Update 140/195 | Steps: 143,360 | Reward: 316.20 | A_Loss: -0.0181 | C_Loss: 315.0584 | Ent: 0.002\n",
            "Update 150/195 | Steps: 153,600 | Reward: 322.38 | A_Loss: -0.0197 | C_Loss: 340.3444 | Ent: 0.003\n",
            "Update 160/195 | Steps: 163,840 | Reward: 319.84 | A_Loss: -0.0299 | C_Loss: 230.3723 | Ent: 0.002\n",
            "Update 170/195 | Steps: 174,080 | Reward: 306.53 | A_Loss: -0.0557 | C_Loss: 285.4741 | Ent: 0.002\n",
            "Update 180/195 | Steps: 184,320 | Reward: 303.47 | A_Loss: -0.0395 | C_Loss: 287.4464 | Ent: 0.004\n",
            "Update 190/195 | Steps: 194,560 | Reward: 304.11 | A_Loss: -0.0696 | C_Loss: 292.3600 | Ent: 0.009\n",
            "    Actions (when tasks): L=49% E=51% C=0%\n",
            "    (486 decisions with tasks / 2012 total)\n",
            "      MPD_0: L=100% E=0% C=0% (120 decisions)\n",
            "      MPD_1: L=100% E=0% C=0% (120 decisions)\n",
            "      LPD_0: L=0% E=100% C=0% (122 decisions)\n",
            "      LPD_1: L=0% E=100% C=0% (124 decisions)\n",
            "reward=308.0\n",
            "  mappo: 314.0 ± 106.6\n",
            "\n",
            "======================================================================\n",
            "TRAINING ON: RURAL_FIELD\n",
            "======================================================================\n",
            "\n",
            "--- mappo ---\n",
            "  Seed 1/3... Update 10/195 | Steps: 10,240 | Reward: 201.51 | A_Loss: -0.1023 | C_Loss: 178.2665 | Ent: 0.351\n",
            "Update 20/195 | Steps: 20,480 | Reward: 363.98 | A_Loss: -0.2095 | C_Loss: 132.5476 | Ent: 0.069\n",
            "Update 30/195 | Steps: 30,720 | Reward: 354.34 | A_Loss: -0.0656 | C_Loss: 122.1565 | Ent: 0.011\n",
            "Update 40/195 | Steps: 40,960 | Reward: 362.96 | A_Loss: -0.1208 | C_Loss: 100.2007 | Ent: 0.002\n",
            "Update 50/195 | Steps: 51,200 | Reward: 349.11 | A_Loss: -0.1335 | C_Loss: 129.4891 | Ent: 0.002\n",
            "Update 60/195 | Steps: 61,440 | Reward: 341.81 | A_Loss: -0.0863 | C_Loss: 105.2354 | Ent: 0.003\n",
            "Update 70/195 | Steps: 71,680 | Reward: 360.99 | A_Loss: -0.0703 | C_Loss: 113.6052 | Ent: 0.005\n",
            "Update 80/195 | Steps: 81,920 | Reward: 352.33 | A_Loss: -0.0834 | C_Loss: 118.0174 | Ent: 0.010\n",
            "Update 90/195 | Steps: 92,160 | Reward: 358.33 | A_Loss: -0.1155 | C_Loss: 118.0409 | Ent: 0.005\n",
            "Update 100/195 | Steps: 102,400 | Reward: 359.72 | A_Loss: -0.0373 | C_Loss: 111.9214 | Ent: 0.006\n",
            "Update 110/195 | Steps: 112,640 | Reward: 347.41 | A_Loss: -0.0177 | C_Loss: 105.8350 | Ent: 0.004\n",
            "Update 120/195 | Steps: 122,880 | Reward: 364.47 | A_Loss: -0.0977 | C_Loss: 94.9709 | Ent: 0.002\n",
            "Update 130/195 | Steps: 133,120 | Reward: 344.47 | A_Loss: -0.0318 | C_Loss: 127.5184 | Ent: 0.002\n",
            "Update 140/195 | Steps: 143,360 | Reward: 350.97 | A_Loss: -0.0486 | C_Loss: 110.1649 | Ent: 0.003\n",
            "Update 150/195 | Steps: 153,600 | Reward: 354.03 | A_Loss: -0.0362 | C_Loss: 124.4227 | Ent: 0.002\n",
            "Update 160/195 | Steps: 163,840 | Reward: 344.77 | A_Loss: -0.0945 | C_Loss: 117.2975 | Ent: 0.023\n",
            "Update 170/195 | Steps: 174,080 | Reward: 357.85 | A_Loss: -0.0424 | C_Loss: 110.1666 | Ent: 0.024\n",
            "Update 180/195 | Steps: 184,320 | Reward: 346.96 | A_Loss: 0.0176 | C_Loss: 98.6871 | Ent: 0.006\n",
            "Update 190/195 | Steps: 194,560 | Reward: 361.62 | A_Loss: -0.0830 | C_Loss: 116.8323 | Ent: 0.008\n",
            "    Actions (when tasks): L=50% E=50% C=0%\n",
            "    (402 decisions with tasks / 2384 total)\n",
            "      MPD_0: L=99% E=1% C=0% (100 decisions)\n",
            "      MPD_1: L=100% E=0% C=0% (100 decisions)\n",
            "      LPD_0: L=0% E=100% C=0% (100 decisions)\n",
            "      LPD_1: L=0% E=100% C=0% (102 decisions)\n",
            "reward=421.2\n",
            "  Seed 2/3... Update 10/195 | Steps: 10,240 | Reward: 204.07 | A_Loss: -0.0854 | C_Loss: 190.1319 | Ent: 0.376\n",
            "Update 20/195 | Steps: 20,480 | Reward: 365.77 | A_Loss: -0.1957 | C_Loss: 143.6050 | Ent: 0.024\n",
            "Update 30/195 | Steps: 30,720 | Reward: 352.56 | A_Loss: -0.0838 | C_Loss: 120.6595 | Ent: 0.044\n",
            "Update 40/195 | Steps: 40,960 | Reward: 361.49 | A_Loss: -0.1301 | C_Loss: 100.3870 | Ent: 0.019\n",
            "Update 50/195 | Steps: 51,200 | Reward: 348.26 | A_Loss: -0.1339 | C_Loss: 130.0092 | Ent: 0.015\n",
            "Update 60/195 | Steps: 61,440 | Reward: 341.48 | A_Loss: -0.0995 | C_Loss: 105.8246 | Ent: 0.024\n",
            "Update 70/195 | Steps: 71,680 | Reward: 360.81 | A_Loss: -0.0723 | C_Loss: 114.0519 | Ent: 0.012\n",
            "Update 80/195 | Steps: 81,920 | Reward: 350.81 | A_Loss: -0.0969 | C_Loss: 118.4795 | Ent: 0.056\n",
            "Update 90/195 | Steps: 92,160 | Reward: 358.14 | A_Loss: -0.1235 | C_Loss: 118.9077 | Ent: 0.004\n",
            "Update 100/195 | Steps: 102,400 | Reward: 360.09 | A_Loss: -0.0619 | C_Loss: 113.4025 | Ent: 0.010\n",
            "Update 110/195 | Steps: 112,640 | Reward: 347.05 | A_Loss: -0.0322 | C_Loss: 105.3425 | Ent: 0.014\n",
            "Update 120/195 | Steps: 122,880 | Reward: 364.66 | A_Loss: -0.1025 | C_Loss: 95.6641 | Ent: 0.006\n",
            "Update 130/195 | Steps: 133,120 | Reward: 343.18 | A_Loss: -0.0175 | C_Loss: 127.4250 | Ent: 0.010\n",
            "Update 140/195 | Steps: 143,360 | Reward: 350.05 | A_Loss: -0.0511 | C_Loss: 110.7955 | Ent: 0.038\n",
            "Update 150/195 | Steps: 153,600 | Reward: 352.68 | A_Loss: -0.0343 | C_Loss: 123.6075 | Ent: 0.009\n",
            "Update 160/195 | Steps: 163,840 | Reward: 345.34 | A_Loss: -0.1186 | C_Loss: 118.5454 | Ent: 0.012\n",
            "Update 170/195 | Steps: 174,080 | Reward: 359.76 | A_Loss: -0.0688 | C_Loss: 110.7001 | Ent: 0.015\n",
            "Update 180/195 | Steps: 184,320 | Reward: 348.55 | A_Loss: 0.0135 | C_Loss: 98.3500 | Ent: 0.005\n",
            "Update 190/195 | Steps: 194,560 | Reward: 361.70 | A_Loss: -0.0654 | C_Loss: 116.4085 | Ent: 0.004\n",
            "    Actions (when tasks): L=50% E=50% C=0%\n",
            "    (403 decisions with tasks / 2364 total)\n",
            "      MPD_0: L=100% E=0% C=0% (100 decisions)\n",
            "      MPD_1: L=100% E=0% C=0% (100 decisions)\n",
            "      LPD_0: L=0% E=100% C=0% (101 decisions)\n",
            "      LPD_1: L=0% E=100% C=0% (102 decisions)\n",
            "reward=324.8\n",
            "  Seed 3/3... Update 10/195 | Steps: 10,240 | Reward: 223.44 | A_Loss: -0.1529 | C_Loss: 166.5225 | Ent: 0.272\n",
            "Update 20/195 | Steps: 20,480 | Reward: 365.36 | A_Loss: -0.1926 | C_Loss: 131.3720 | Ent: 0.059\n",
            "Update 30/195 | Steps: 30,720 | Reward: 352.57 | A_Loss: -0.0696 | C_Loss: 121.9726 | Ent: 0.009\n",
            "Update 40/195 | Steps: 40,960 | Reward: 362.96 | A_Loss: -0.1213 | C_Loss: 100.4013 | Ent: 0.010\n",
            "Update 50/195 | Steps: 51,200 | Reward: 348.71 | A_Loss: -0.1217 | C_Loss: 129.8929 | Ent: 0.012\n",
            "Update 60/195 | Steps: 61,440 | Reward: 341.79 | A_Loss: -0.0932 | C_Loss: 105.4818 | Ent: 0.007\n",
            "Update 70/195 | Steps: 71,680 | Reward: 360.57 | A_Loss: -0.0876 | C_Loss: 115.1990 | Ent: 0.005\n",
            "Update 80/195 | Steps: 81,920 | Reward: 352.82 | A_Loss: -0.0823 | C_Loss: 118.8188 | Ent: 0.003\n",
            "Update 90/195 | Steps: 92,160 | Reward: 358.34 | A_Loss: -0.1266 | C_Loss: 118.7475 | Ent: 0.005\n",
            "Update 100/195 | Steps: 102,400 | Reward: 360.14 | A_Loss: -0.0277 | C_Loss: 113.0093 | Ent: 0.004\n",
            "Update 110/195 | Steps: 112,640 | Reward: 346.58 | A_Loss: -0.0342 | C_Loss: 105.8222 | Ent: 0.003\n",
            "Update 120/195 | Steps: 122,880 | Reward: 364.67 | A_Loss: -0.0981 | C_Loss: 95.3277 | Ent: 0.001\n",
            "Update 130/195 | Steps: 133,120 | Reward: 344.51 | A_Loss: -0.0141 | C_Loss: 129.0250 | Ent: 0.001\n",
            "Update 140/195 | Steps: 143,360 | Reward: 350.97 | A_Loss: -0.0410 | C_Loss: 110.3941 | Ent: 0.001\n",
            "Update 150/195 | Steps: 153,600 | Reward: 354.03 | A_Loss: -0.0404 | C_Loss: 124.4845 | Ent: 0.003\n",
            "Update 160/195 | Steps: 163,840 | Reward: 345.71 | A_Loss: -0.1247 | C_Loss: 119.7878 | Ent: 0.001\n",
            "Update 170/195 | Steps: 174,080 | Reward: 359.01 | A_Loss: -0.0292 | C_Loss: 109.7333 | Ent: 0.001\n",
            "Update 180/195 | Steps: 184,320 | Reward: 348.58 | A_Loss: 0.0374 | C_Loss: 98.6001 | Ent: 0.000\n",
            "Update 190/195 | Steps: 194,560 | Reward: 361.80 | A_Loss: -0.0647 | C_Loss: 116.3301 | Ent: 0.000\n",
            "    Actions (when tasks): L=50% E=50% C=0%\n",
            "    (402 decisions with tasks / 2264 total)\n",
            "      MPD_0: L=100% E=0% C=0% (100 decisions)\n",
            "      MPD_1: L=100% E=0% C=0% (100 decisions)\n",
            "      LPD_0: L=0% E=100% C=0% (101 decisions)\n",
            "      LPD_1: L=0% E=100% C=0% (101 decisions)\n",
            "reward=367.4\n",
            "  mappo: 371.1 ± 72.3\n",
            "\n",
            "======================================================================\n",
            "TRAINING ON: VARIABLE_TERRAIN\n",
            "======================================================================\n",
            "\n",
            "--- mappo ---\n",
            "  Seed 1/3... Update 10/195 | Steps: 10,240 | Reward: 74.66 | A_Loss: -0.3166 | C_Loss: 437.7670 | Ent: 0.402\n",
            "Update 20/195 | Steps: 20,480 | Reward: 172.01 | A_Loss: -0.0870 | C_Loss: 242.7028 | Ent: 0.250\n",
            "Update 30/195 | Steps: 30,720 | Reward: 178.98 | A_Loss: -0.0995 | C_Loss: 203.0793 | Ent: 0.207\n",
            "Update 40/195 | Steps: 40,960 | Reward: 183.40 | A_Loss: -0.1022 | C_Loss: 211.0861 | Ent: 0.207\n",
            "Update 50/195 | Steps: 51,200 | Reward: 187.13 | A_Loss: -0.0193 | C_Loss: 177.6752 | Ent: 0.186\n",
            "Update 60/195 | Steps: 61,440 | Reward: 179.86 | A_Loss: -0.0408 | C_Loss: 212.2583 | Ent: 0.078\n",
            "Update 70/195 | Steps: 71,680 | Reward: 183.24 | A_Loss: -0.0599 | C_Loss: 186.2109 | Ent: 0.132\n",
            "Update 80/195 | Steps: 81,920 | Reward: 182.83 | A_Loss: -0.0716 | C_Loss: 168.3624 | Ent: 0.210\n",
            "Update 90/195 | Steps: 92,160 | Reward: 198.18 | A_Loss: -0.0683 | C_Loss: 108.5588 | Ent: 0.332\n",
            "Update 100/195 | Steps: 102,400 | Reward: 197.04 | A_Loss: -0.0506 | C_Loss: 80.2712 | Ent: 0.313\n",
            "Update 110/195 | Steps: 112,640 | Reward: 204.37 | A_Loss: -0.0415 | C_Loss: 135.8028 | Ent: 0.300\n",
            "Update 120/195 | Steps: 122,880 | Reward: 199.27 | A_Loss: -0.1304 | C_Loss: 80.6262 | Ent: 0.341\n",
            "Update 130/195 | Steps: 133,120 | Reward: 191.82 | A_Loss: -0.1052 | C_Loss: 100.8626 | Ent: 0.328\n",
            "Update 140/195 | Steps: 143,360 | Reward: 195.84 | A_Loss: -0.0069 | C_Loss: 86.2050 | Ent: 0.302\n",
            "Update 150/195 | Steps: 153,600 | Reward: 195.59 | A_Loss: -0.0635 | C_Loss: 87.2971 | Ent: 0.294\n",
            "Update 160/195 | Steps: 163,840 | Reward: 204.87 | A_Loss: -0.0041 | C_Loss: 69.4899 | Ent: 0.289\n",
            "Update 170/195 | Steps: 174,080 | Reward: 202.22 | A_Loss: -0.0725 | C_Loss: 94.8831 | Ent: 0.275\n",
            "Update 180/195 | Steps: 184,320 | Reward: 197.69 | A_Loss: -0.0206 | C_Loss: 160.5587 | Ent: 0.289\n",
            "Update 190/195 | Steps: 194,560 | Reward: 206.53 | A_Loss: -0.0745 | C_Loss: 61.0323 | Ent: 0.257\n",
            "    Actions (when tasks): L=74% E=25% C=0%\n",
            "    (493 decisions with tasks / 1820 total)\n",
            "      MPD_0: L=100% E=0% C=0% (120 decisions)\n",
            "      MPD_1: L=100% E=0% C=0% (120 decisions)\n",
            "      LPD_0: L=50% E=48% C=2% (126 decisions)\n",
            "      LPD_1: L=50% E=50% C=0% (127 decisions)\n",
            "reward=190.6\n",
            "  Seed 2/3... Update 10/195 | Steps: 10,240 | Reward: 27.73 | A_Loss: -0.2745 | C_Loss: 493.3555 | Ent: 0.505\n",
            "Update 20/195 | Steps: 20,480 | Reward: 175.01 | A_Loss: -0.0460 | C_Loss: 206.7552 | Ent: 0.328\n",
            "Update 30/195 | Steps: 30,720 | Reward: 179.90 | A_Loss: -0.0824 | C_Loss: 212.1001 | Ent: 0.253\n",
            "Update 40/195 | Steps: 40,960 | Reward: 193.72 | A_Loss: -0.1448 | C_Loss: 150.4361 | Ent: 0.306\n",
            "Update 50/195 | Steps: 51,200 | Reward: 201.35 | A_Loss: -0.0497 | C_Loss: 107.6767 | Ent: 0.341\n",
            "Update 60/195 | Steps: 61,440 | Reward: 204.60 | A_Loss: -0.0615 | C_Loss: 113.7775 | Ent: 0.335\n",
            "Update 70/195 | Steps: 71,680 | Reward: 193.98 | A_Loss: -0.0084 | C_Loss: 181.5271 | Ent: 0.363\n",
            "Update 80/195 | Steps: 81,920 | Reward: 195.51 | A_Loss: -0.0457 | C_Loss: 135.0198 | Ent: 0.350\n",
            "Update 90/195 | Steps: 92,160 | Reward: 199.18 | A_Loss: -0.0760 | C_Loss: 90.4440 | Ent: 0.341\n",
            "Update 100/195 | Steps: 102,400 | Reward: 201.97 | A_Loss: -0.0653 | C_Loss: 106.0499 | Ent: 0.340\n",
            "Update 110/195 | Steps: 112,640 | Reward: 203.45 | A_Loss: -0.1002 | C_Loss: 107.4008 | Ent: 0.291\n",
            "Update 120/195 | Steps: 122,880 | Reward: 193.17 | A_Loss: -0.0660 | C_Loss: 94.9095 | Ent: 0.290\n",
            "Update 130/195 | Steps: 133,120 | Reward: 198.36 | A_Loss: -0.0102 | C_Loss: 98.2438 | Ent: 0.289\n",
            "Update 140/195 | Steps: 143,360 | Reward: 199.19 | A_Loss: -0.0402 | C_Loss: 112.1758 | Ent: 0.246\n",
            "Update 150/195 | Steps: 153,600 | Reward: 199.04 | A_Loss: -0.0290 | C_Loss: 73.6355 | Ent: 0.256\n",
            "Update 160/195 | Steps: 163,840 | Reward: 202.49 | A_Loss: 0.0217 | C_Loss: 73.9524 | Ent: 0.243\n",
            "Update 170/195 | Steps: 174,080 | Reward: 202.00 | A_Loss: -0.0603 | C_Loss: 61.5938 | Ent: 0.268\n",
            "Update 180/195 | Steps: 184,320 | Reward: 198.85 | A_Loss: -0.0536 | C_Loss: 88.9850 | Ent: 0.272\n",
            "Update 190/195 | Steps: 194,560 | Reward: 200.64 | A_Loss: -0.0689 | C_Loss: 83.0210 | Ent: 0.248\n",
            "    Actions (when tasks): L=72% E=28% C=0%\n",
            "    (506 decisions with tasks / 1764 total)\n",
            "      MPD_0: L=100% E=0% C=0% (120 decisions)\n",
            "      MPD_1: L=100% E=0% C=0% (120 decisions)\n",
            "      LPD_0: L=48% E=52% C=0% (137 decisions)\n",
            "      LPD_1: L=47% E=53% C=0% (129 decisions)\n",
            "reward=202.5\n",
            "  Seed 3/3... Update 10/195 | Steps: 10,240 | Reward: 72.13 | A_Loss: -0.3354 | C_Loss: 420.7813 | Ent: 0.423\n",
            "Update 20/195 | Steps: 20,480 | Reward: 189.62 | A_Loss: -0.1001 | C_Loss: 260.6562 | Ent: 0.214\n",
            "Update 30/195 | Steps: 30,720 | Reward: 176.62 | A_Loss: -0.0969 | C_Loss: 202.4000 | Ent: 0.210\n",
            "Update 40/195 | Steps: 40,960 | Reward: 194.74 | A_Loss: -0.1103 | C_Loss: 189.8232 | Ent: 0.334\n",
            "Update 50/195 | Steps: 51,200 | Reward: 193.50 | A_Loss: -0.0982 | C_Loss: 102.2579 | Ent: 0.343\n",
            "Update 60/195 | Steps: 61,440 | Reward: 197.52 | A_Loss: -0.0564 | C_Loss: 68.3382 | Ent: 0.316\n",
            "Update 70/195 | Steps: 71,680 | Reward: 196.04 | A_Loss: -0.0935 | C_Loss: 106.6587 | Ent: 0.303\n",
            "Update 80/195 | Steps: 81,920 | Reward: 194.87 | A_Loss: 0.1352 | C_Loss: 94.6632 | Ent: 0.331\n",
            "Update 90/195 | Steps: 92,160 | Reward: 203.16 | A_Loss: -0.0297 | C_Loss: 138.6966 | Ent: 0.299\n",
            "Update 100/195 | Steps: 102,400 | Reward: 189.02 | A_Loss: -0.0614 | C_Loss: 105.9746 | Ent: 0.290\n",
            "Update 110/195 | Steps: 112,640 | Reward: 198.56 | A_Loss: -0.0214 | C_Loss: 80.1547 | Ent: 0.291\n",
            "Update 120/195 | Steps: 122,880 | Reward: 203.48 | A_Loss: -0.0618 | C_Loss: 121.5634 | Ent: 0.296\n",
            "Update 130/195 | Steps: 133,120 | Reward: 208.45 | A_Loss: -0.0539 | C_Loss: 62.3392 | Ent: 0.285\n",
            "Update 140/195 | Steps: 143,360 | Reward: 200.72 | A_Loss: -0.0448 | C_Loss: 80.9669 | Ent: 0.276\n",
            "Update 150/195 | Steps: 153,600 | Reward: 201.26 | A_Loss: -0.0490 | C_Loss: 85.2593 | Ent: 0.247\n",
            "Update 160/195 | Steps: 163,840 | Reward: 207.33 | A_Loss: -0.0654 | C_Loss: 70.4260 | Ent: 0.215\n",
            "Update 170/195 | Steps: 174,080 | Reward: 210.71 | A_Loss: -0.0764 | C_Loss: 59.4724 | Ent: 0.202\n",
            "Update 180/195 | Steps: 184,320 | Reward: 211.50 | A_Loss: -0.1249 | C_Loss: 56.5633 | Ent: 0.168\n",
            "Update 190/195 | Steps: 194,560 | Reward: 214.20 | A_Loss: -0.0388 | C_Loss: 51.4444 | Ent: 0.154\n",
            "    Actions (when tasks): L=76% E=24% C=0%\n",
            "    (495 decisions with tasks / 1708 total)\n",
            "      MPD_0: L=100% E=0% C=0% (120 decisions)\n",
            "      MPD_1: L=100% E=0% C=0% (120 decisions)\n",
            "      LPD_0: L=57% E=43% C=0% (124 decisions)\n",
            "      LPD_1: L=49% E=51% C=0% (131 decisions)\n",
            "reward=226.3\n",
            "  mappo: 206.5 ± 33.0\n",
            "\n",
            "======================================================================\n",
            "TRAINING ON: NETWORK_AWARE\n",
            "======================================================================\n",
            "\n",
            "--- mappo ---\n",
            "  Seed 1/3... Update 10/195 | Steps: 10,240 | Reward: 55.99 | A_Loss: -0.3253 | C_Loss: 437.8170 | Ent: 0.460\n",
            "Update 20/195 | Steps: 20,480 | Reward: 112.74 | A_Loss: -0.1116 | C_Loss: 263.7862 | Ent: 0.132\n",
            "Update 30/195 | Steps: 30,720 | Reward: 107.25 | A_Loss: -0.0691 | C_Loss: 221.2430 | Ent: 0.096\n",
            "Update 40/195 | Steps: 40,960 | Reward: 117.98 | A_Loss: -0.1668 | C_Loss: 242.7851 | Ent: 0.027\n",
            "Update 50/195 | Steps: 51,200 | Reward: 115.04 | A_Loss: -0.1110 | C_Loss: 234.5216 | Ent: 0.008\n",
            "Update 60/195 | Steps: 61,440 | Reward: 114.49 | A_Loss: -0.1329 | C_Loss: 237.2214 | Ent: 0.007\n",
            "Update 70/195 | Steps: 71,680 | Reward: 121.79 | A_Loss: -0.1190 | C_Loss: 279.6801 | Ent: 0.020\n",
            "Update 80/195 | Steps: 81,920 | Reward: 114.72 | A_Loss: -0.1608 | C_Loss: 275.2853 | Ent: 0.078\n",
            "Update 90/195 | Steps: 92,160 | Reward: 105.64 | A_Loss: -0.1326 | C_Loss: 214.4496 | Ent: 0.062\n",
            "Update 100/195 | Steps: 102,400 | Reward: 115.89 | A_Loss: -0.1286 | C_Loss: 238.4613 | Ent: 0.077\n",
            "Update 110/195 | Steps: 112,640 | Reward: 110.38 | A_Loss: -0.1418 | C_Loss: 238.0599 | Ent: 0.121\n",
            "Update 120/195 | Steps: 122,880 | Reward: 108.43 | A_Loss: -0.1077 | C_Loss: 284.9146 | Ent: 0.063\n",
            "Update 130/195 | Steps: 133,120 | Reward: 104.42 | A_Loss: -0.1489 | C_Loss: 206.7273 | Ent: 0.019\n",
            "Update 140/195 | Steps: 143,360 | Reward: 111.35 | A_Loss: -0.1121 | C_Loss: 227.5620 | Ent: 0.059\n",
            "Update 150/195 | Steps: 153,600 | Reward: 117.91 | A_Loss: -0.1158 | C_Loss: 223.3739 | Ent: 0.035\n",
            "Update 160/195 | Steps: 163,840 | Reward: 110.98 | A_Loss: -0.1875 | C_Loss: 229.7247 | Ent: 0.018\n",
            "Update 170/195 | Steps: 174,080 | Reward: 116.94 | A_Loss: -0.1203 | C_Loss: 202.2717 | Ent: 0.018\n",
            "Update 180/195 | Steps: 184,320 | Reward: 114.94 | A_Loss: -0.1815 | C_Loss: 286.9632 | Ent: 0.011\n",
            "Update 190/195 | Steps: 194,560 | Reward: 110.42 | A_Loss: -0.0860 | C_Loss: 224.8841 | Ent: 0.016\n",
            "    Actions (when tasks): L=48% E=51% C=1%\n",
            "    (500 decisions with tasks / 1732 total)\n",
            "      MPD_0: L=100% E=0% C=0% (120 decisions)\n",
            "      MPD_1: L=100% E=0% C=0% (120 decisions)\n",
            "      LPD_0: L=0% E=99% C=1% (129 decisions)\n",
            "      LPD_1: L=1% E=98% C=2% (131 decisions)\n",
            "reward=105.9\n",
            "  Seed 2/3... Update 10/195 | Steps: 10,240 | Reward: 49.36 | A_Loss: -0.3421 | C_Loss: 360.1291 | Ent: 0.476\n",
            "Update 20/195 | Steps: 20,480 | Reward: 114.18 | A_Loss: -0.1424 | C_Loss: 209.5557 | Ent: 0.377\n",
            "Update 30/195 | Steps: 30,720 | Reward: 119.11 | A_Loss: -0.0480 | C_Loss: 184.7893 | Ent: 0.231\n",
            "Update 40/195 | Steps: 40,960 | Reward: 128.98 | A_Loss: -0.1577 | C_Loss: 160.9309 | Ent: 0.272\n",
            "Update 50/195 | Steps: 51,200 | Reward: 117.60 | A_Loss: -0.1049 | C_Loss: 137.2303 | Ent: 0.344\n",
            "Update 60/195 | Steps: 61,440 | Reward: 128.25 | A_Loss: -0.1426 | C_Loss: 146.7791 | Ent: 0.279\n",
            "Update 70/195 | Steps: 71,680 | Reward: 122.10 | A_Loss: -0.1861 | C_Loss: 157.1861 | Ent: 0.257\n",
            "Update 80/195 | Steps: 81,920 | Reward: 115.71 | A_Loss: -0.1755 | C_Loss: 201.2176 | Ent: 0.171\n",
            "Update 90/195 | Steps: 92,160 | Reward: 123.08 | A_Loss: -0.1194 | C_Loss: 212.3862 | Ent: 0.160\n",
            "Update 100/195 | Steps: 102,400 | Reward: 117.54 | A_Loss: -0.1024 | C_Loss: 228.8931 | Ent: 0.129\n",
            "Update 110/195 | Steps: 112,640 | Reward: 114.35 | A_Loss: -0.1639 | C_Loss: 214.5533 | Ent: 0.104\n",
            "Update 120/195 | Steps: 122,880 | Reward: 110.65 | A_Loss: -0.1137 | C_Loss: 227.1409 | Ent: 0.066\n",
            "Update 130/195 | Steps: 133,120 | Reward: 108.68 | A_Loss: -0.1136 | C_Loss: 210.7015 | Ent: 0.082\n",
            "Update 140/195 | Steps: 143,360 | Reward: 112.28 | A_Loss: -0.1390 | C_Loss: 198.8472 | Ent: 0.089\n",
            "Update 150/195 | Steps: 153,600 | Reward: 103.88 | A_Loss: -0.1491 | C_Loss: 193.8769 | Ent: 0.080\n",
            "Update 160/195 | Steps: 163,840 | Reward: 116.98 | A_Loss: -0.0926 | C_Loss: 245.9013 | Ent: 0.066\n",
            "Update 170/195 | Steps: 174,080 | Reward: 111.86 | A_Loss: -0.0926 | C_Loss: 242.7656 | Ent: 0.038\n",
            "Update 180/195 | Steps: 184,320 | Reward: 121.10 | A_Loss: -0.0676 | C_Loss: 278.9853 | Ent: 0.022\n",
            "Update 190/195 | Steps: 194,560 | Reward: 107.88 | A_Loss: -0.1020 | C_Loss: 209.8953 | Ent: 0.030\n",
            "    Actions (when tasks): L=49% E=51% C=0%\n",
            "    (505 decisions with tasks / 1716 total)\n",
            "      MPD_0: L=100% E=0% C=0% (120 decisions)\n",
            "      MPD_1: L=100% E=0% C=0% (120 decisions)\n",
            "      LPD_0: L=2% E=98% C=0% (136 decisions)\n",
            "      LPD_1: L=2% E=98% C=0% (129 decisions)\n",
            "reward=108.7\n",
            "  Seed 3/3... Update 10/195 | Steps: 10,240 | Reward: 24.63 | A_Loss: -0.3232 | C_Loss: 433.8493 | Ent: 0.410\n",
            "Update 20/195 | Steps: 20,480 | Reward: 112.58 | A_Loss: -0.1117 | C_Loss: 179.6965 | Ent: 0.387\n",
            "Update 30/195 | Steps: 30,720 | Reward: 121.18 | A_Loss: -0.1140 | C_Loss: 196.5584 | Ent: 0.286\n",
            "Update 40/195 | Steps: 40,960 | Reward: 121.81 | A_Loss: -0.1089 | C_Loss: 165.7209 | Ent: 0.253\n",
            "Update 50/195 | Steps: 51,200 | Reward: 120.92 | A_Loss: -0.1381 | C_Loss: 146.2445 | Ent: 0.321\n",
            "Update 60/195 | Steps: 61,440 | Reward: 117.81 | A_Loss: -0.1534 | C_Loss: 153.7945 | Ent: 0.390\n",
            "Update 70/195 | Steps: 71,680 | Reward: 118.85 | A_Loss: -0.1678 | C_Loss: 136.4954 | Ent: 0.353\n",
            "Update 80/195 | Steps: 81,920 | Reward: 127.17 | A_Loss: -0.1230 | C_Loss: 121.3005 | Ent: 0.348\n",
            "Update 90/195 | Steps: 92,160 | Reward: 125.08 | A_Loss: -0.2073 | C_Loss: 96.4873 | Ent: 0.321\n",
            "Update 100/195 | Steps: 102,400 | Reward: 130.53 | A_Loss: -0.2542 | C_Loss: 112.0362 | Ent: 0.292\n",
            "Update 110/195 | Steps: 112,640 | Reward: 129.92 | A_Loss: -0.1603 | C_Loss: 125.8241 | Ent: 0.260\n",
            "Update 120/195 | Steps: 122,880 | Reward: 122.48 | A_Loss: -0.1333 | C_Loss: 197.7777 | Ent: 0.169\n",
            "Update 130/195 | Steps: 133,120 | Reward: 111.58 | A_Loss: -0.0709 | C_Loss: 178.0941 | Ent: 0.188\n",
            "Update 140/195 | Steps: 143,360 | Reward: 126.51 | A_Loss: -0.1369 | C_Loss: 194.1506 | Ent: 0.182\n",
            "Update 150/195 | Steps: 153,600 | Reward: 121.26 | A_Loss: -0.1113 | C_Loss: 216.3870 | Ent: 0.115\n",
            "Update 160/195 | Steps: 163,840 | Reward: 122.32 | A_Loss: -0.1269 | C_Loss: 198.0017 | Ent: 0.147\n",
            "Update 170/195 | Steps: 174,080 | Reward: 111.31 | A_Loss: -0.0869 | C_Loss: 235.3880 | Ent: 0.063\n",
            "Update 180/195 | Steps: 184,320 | Reward: 121.30 | A_Loss: -0.1049 | C_Loss: 225.3835 | Ent: 0.079\n",
            "Update 190/195 | Steps: 194,560 | Reward: 123.22 | A_Loss: -0.1254 | C_Loss: 219.9931 | Ent: 0.056\n",
            "    Actions (when tasks): L=49% E=51% C=0%\n",
            "    (497 decisions with tasks / 1824 total)\n",
            "      MPD_0: L=100% E=0% C=0% (120 decisions)\n",
            "      MPD_1: L=100% E=0% C=0% (120 decisions)\n",
            "      LPD_0: L=1% E=99% C=0% (130 decisions)\n",
            "      LPD_1: L=2% E=98% C=0% (127 decisions)\n",
            "reward=161.7\n",
            "  mappo: 125.4 ± 66.3\n",
            "\n",
            "✓ MARL training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CQkFiJqcbl4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PHASE 3: GENERATING PER-SCENARIO RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for scenario in SCENARIOS:\n",
        "    print(f\"\\n--- {scenario} ---\")\n",
        "\n",
        "    scenario_dir = f\"{OUTPUT_DIR}/{scenario}\"\n",
        "    Path(scenario_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Convert baseline collectors to format expected by visualization functions\n",
        "    baseline_for_viz = {}\n",
        "    for name, collector in all_baseline_results[scenario].items():\n",
        "        s = collector.summary()\n",
        "        baseline_for_viz[name] = s\n",
        "\n",
        "    # Save comprehensive checkpoint\n",
        "    save_comprehensive_checkpoint(\n",
        "        scenario_dir,\n",
        "        all_marl_results[scenario],\n",
        "        baseline_results=all_baseline_results[scenario],\n",
        "        config={\n",
        "            'scenario': scenario,\n",
        "            'total_timesteps': TOTAL_TIMESTEPS,\n",
        "            'n_seeds': N_SEEDS,\n",
        "            'n_eval_episodes': N_EVAL_EPISODES,\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\\n✓ Per-scenario results saved\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP0rKsEvboib",
        "outputId": "e3fe7aea-3fff-47fa-b0d7-4eba74bb19ff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PHASE 3: GENERATING PER-SCENARIO RESULTS\n",
            "======================================================================\n",
            "\n",
            "--- streaming_hard ---\n",
            "✓ Saved summary table to ijcnn_results/streaming_hard/summary_table.csv\n",
            "✓ Saved LaTeX table to ijcnn_results/streaming_hard/summary_table.tex\n",
            "✓ Generated figures in ijcnn_results/streaming_hard/figures/\n",
            "  - reward_comparison.png\n",
            "  - completion_comparison.png\n",
            "  - ontime_comparison.png\n",
            "  - latency_comparison.png\n",
            "  - battery_comparison.png\n",
            "  - action_distribution.png\n",
            "  - multi_metric_comparison.png\n",
            "\n",
            "================================================================================\n",
            "COMPREHENSIVE RESULTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Algorithm                     Reward    Comp%  OnTime%    Latency   Battery% Actions (L/E/C)\n",
            "-----------------------------------------------------------------------------------------------\n",
            "\n",
            "[BASELINES]\n",
            "Local-Only               -6693.2±0.0    83.3%    83.3%       1.2      92.0% 100/0/0\n",
            "Edge-Only                209.3±151.4    72.6%    72.6%      19.7       0.0% 0/100/0\n",
            "Cloud-Only                 2.1±132.5    72.6%    72.6%      19.7       0.0% 0/0/100\n",
            "Round-Robin              -170.3±93.8    84.2%    84.2%       9.9      48.3% 34/33/33\n",
            "Random                   121.8±111.9    82.6%    82.6%      11.6      42.9% 34/33/33\n",
            "Multi-Metric             305.5±109.4    84.8%    84.8%      10.5      34.1% 47/53/0\n",
            "Multi-Metric-BW          245.0±133.9    78.3%    78.3%      14.8      17.0% 22/78/0\n",
            "Multi-Metric-Urgent      295.7±106.3    85.8%    85.8%       9.7      37.2% 49/49/2\n",
            "Latency-Greedy             2.1±132.5    72.6%    72.6%      19.7       0.0% 0/0/100\n",
            "\n",
            "[MARL ALGORITHMS]\n",
            "mappo                    314.0±106.6    83.6%    83.6%       7.6      42.0% 49/51/0\n",
            "\n",
            "================================================================================\n",
            "\n",
            "🏆 Best by Reward: mappo (314.0)\n",
            "\n",
            "✓ Comprehensive checkpoint saved to ijcnn_results/streaming_hard\n",
            "\n",
            "--- rural_field ---\n",
            "✓ Saved summary table to ijcnn_results/rural_field/summary_table.csv\n",
            "✓ Saved LaTeX table to ijcnn_results/rural_field/summary_table.tex\n",
            "✓ Generated figures in ijcnn_results/rural_field/figures/\n",
            "  - reward_comparison.png\n",
            "  - completion_comparison.png\n",
            "  - ontime_comparison.png\n",
            "  - latency_comparison.png\n",
            "  - battery_comparison.png\n",
            "  - action_distribution.png\n",
            "  - multi_metric_comparison.png\n",
            "\n",
            "================================================================================\n",
            "COMPREHENSIVE RESULTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Algorithm                     Reward    Comp%  OnTime%    Latency   Battery% Actions (L/E/C)\n",
            "-----------------------------------------------------------------------------------------------\n",
            "\n",
            "[BASELINES]\n",
            "Local-Only               -5057.3±0.0    95.0%    95.0%       0.5      80.0% 100/0/0\n",
            "Edge-Only                 234.8±99.4    81.4%    81.4%      21.9       0.0% 0/100/0\n",
            "Cloud-Only                 53.3±88.9    81.4%    81.4%      21.9       0.0% 0/0/100\n",
            "Round-Robin               141.8±77.8    87.3%    87.3%      13.6      30.2% 33/33/33\n",
            "Random                    143.4±70.7    88.6%    88.6%      13.3      32.0% 34/33/33\n",
            "Multi-Metric              329.4±87.4    89.2%    89.2%      11.9      25.1% 48/52/0\n",
            "Multi-Metric-BW           249.0±89.9    84.4%    84.4%      17.2      12.1% 21/79/0\n",
            "Multi-Metric-Urgent       321.0±82.4    89.4%    89.4%      11.7      25.5% 49/49/2\n",
            "Latency-Greedy             53.3±88.9    81.4%    81.4%      21.9       0.0% 0/0/100\n",
            "\n",
            "[MARL ALGORITHMS]\n",
            "mappo                     371.1±72.3    90.0%    90.0%       9.8      30.0% 50/50/0\n",
            "\n",
            "================================================================================\n",
            "\n",
            "🏆 Best by Reward: mappo (371.1)\n",
            "\n",
            "✓ Comprehensive checkpoint saved to ijcnn_results/rural_field\n",
            "\n",
            "--- variable_terrain ---\n",
            "✓ Saved summary table to ijcnn_results/variable_terrain/summary_table.csv\n",
            "✓ Saved LaTeX table to ijcnn_results/variable_terrain/summary_table.tex\n",
            "✓ Generated figures in ijcnn_results/variable_terrain/figures/\n",
            "  - reward_comparison.png\n",
            "  - completion_comparison.png\n",
            "  - ontime_comparison.png\n",
            "  - latency_comparison.png\n",
            "  - battery_comparison.png\n",
            "  - action_distribution.png\n",
            "  - multi_metric_comparison.png\n",
            "\n",
            "================================================================================\n",
            "COMPREHENSIVE RESULTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Algorithm                     Reward    Comp%  OnTime%    Latency   Battery% Actions (L/E/C)\n",
            "-----------------------------------------------------------------------------------------------\n",
            "\n",
            "[BASELINES]\n",
            "Local-Only               -6467.2±0.0    87.5%    87.5%       1.3      86.0% 100/0/0\n",
            "Edge-Only                -230.3±79.3    22.5%    22.5%      16.8       0.0% 0/100/0\n",
            "Cloud-Only               -377.3±66.4    22.5%    22.5%      16.8       0.0% 0/0/100\n",
            "Round-Robin              -327.4±62.8    58.9%    58.9%       3.8      47.9% 33/33/33\n",
            "Random                   -175.5±49.3    48.0%    48.0%       5.5      36.2% 34/33/33\n",
            "Multi-Metric               55.5±72.1    59.6%    59.6%       3.4      39.8% 51/49/0\n",
            "Multi-Metric-BW           -66.8±53.6    49.2%    49.2%       5.4      29.6% 35/65/0\n",
            "Multi-Metric-Urgent        48.0±68.3    60.1%    60.1%       3.2      40.4% 52/46/3\n",
            "Latency-Greedy           -377.3±66.4    22.5%    22.5%      16.8       0.0% 0/0/100\n",
            "\n",
            "[MARL ALGORITHMS]\n",
            "mappo                     206.5±33.0    80.6%    80.6%       1.0      74.4% 74/26/0\n",
            "\n",
            "================================================================================\n",
            "\n",
            "🏆 Best by Reward: mappo (206.5)\n",
            "\n",
            "✓ Comprehensive checkpoint saved to ijcnn_results/variable_terrain\n",
            "\n",
            "--- network_aware ---\n",
            "✓ Saved summary table to ijcnn_results/network_aware/summary_table.csv\n",
            "✓ Saved LaTeX table to ijcnn_results/network_aware/summary_table.tex\n",
            "✓ Generated figures in ijcnn_results/network_aware/figures/\n",
            "  - reward_comparison.png\n",
            "  - completion_comparison.png\n",
            "  - ontime_comparison.png\n",
            "  - latency_comparison.png\n",
            "  - battery_comparison.png\n",
            "  - action_distribution.png\n",
            "  - multi_metric_comparison.png\n",
            "\n",
            "================================================================================\n",
            "COMPREHENSIVE RESULTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Algorithm                     Reward    Comp%  OnTime%    Latency   Battery% Actions (L/E/C)\n",
            "-----------------------------------------------------------------------------------------------\n",
            "\n",
            "[BASELINES]\n",
            "Local-Only               -6693.2±0.0    83.3%    83.3%       1.2      92.0% 100/0/0\n",
            "Edge-Only                -235.4±71.6    21.7%    21.7%      19.9       0.0% 0/100/0\n",
            "Cloud-Only               -381.4±60.5    21.7%    21.7%      19.9       0.0% 0/0/100\n",
            "Round-Robin              -413.3±53.7    55.3%    55.3%       4.1      51.1% 34/33/33\n",
            "Random                   -184.5±71.2    50.3%    50.3%       5.7      45.3% 34/33/33\n",
            "Multi-Metric                5.7±61.4    59.3%    59.3%       3.4      47.5% 51/48/0\n",
            "Multi-Metric-BW           -84.7±58.9    48.4%    48.4%       4.9      36.8% 37/63/0\n",
            "Multi-Metric-Urgent         1.0±58.0    59.9%    59.9%       3.3      48.1% 52/46/2\n",
            "Latency-Greedy           -381.4±60.5    21.7%    21.7%      19.9       0.0% 0/0/100\n",
            "\n",
            "[MARL ALGORITHMS]\n",
            "mappo                     125.4±66.3    61.9%    61.9%       3.4      43.3% 49/51/0\n",
            "\n",
            "================================================================================\n",
            "\n",
            "🏆 Best by Reward: mappo (125.4)\n",
            "\n",
            "✓ Comprehensive checkpoint saved to ijcnn_results/network_aware\n",
            "\n",
            "✓ Per-scenario results saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OIcVG0KIbpjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PHASE 4: CROSS-SCENARIO AGGREGATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Build aggregate summary across all scenarios\n",
        "aggregate_rows = []\n",
        "\n",
        "# Baselines\n",
        "for scenario in SCENARIOS:\n",
        "    for name, collector in all_baseline_results[scenario].items():\n",
        "        s = collector.summary()\n",
        "        aggregate_rows.append({\n",
        "            'scenario': scenario,\n",
        "            'algorithm': name,\n",
        "            'type': 'Baseline',\n",
        "            'reward_mean': s['reward_mean'],\n",
        "            'reward_std': s['reward_std'],\n",
        "            'completion': s['completion'],\n",
        "            'on_time_rate': s['on_time_rate'],\n",
        "            'battery_used_pct': s.get('battery_used_pct', 0),\n",
        "            'avg_latency': s.get('avg_latency', 0),\n",
        "            'local_pct': s['local_pct'],\n",
        "            'edge_pct': s['edge_pct'],\n",
        "            'cloud_pct': s['cloud_pct'],\n",
        "        })\n",
        "\n",
        "# MARL\n",
        "for scenario in SCENARIOS:\n",
        "    for alg, stats in all_marl_results[scenario].items():\n",
        "        aggregate_rows.append({\n",
        "            'scenario': scenario,\n",
        "            'algorithm': alg,\n",
        "            'type': 'MARL',\n",
        "            'reward_mean': stats['reward_mean'],\n",
        "            'reward_std': stats['reward_std'],\n",
        "            'completion': stats['completion'],\n",
        "            'on_time_rate': stats['on_time_rate'],\n",
        "            'battery_used_pct': stats.get('battery_used_pct', 0),\n",
        "            'avg_latency': stats.get('avg_latency', 0),\n",
        "            'local_pct': stats['local_pct'],\n",
        "            'edge_pct': stats['edge_pct'],\n",
        "            'cloud_pct': stats['cloud_pct'],\n",
        "        })\n",
        "\n",
        "aggregate_df = pd.DataFrame(aggregate_rows)\n",
        "aggregate_df.to_csv(f\"{OUTPUT_DIR}/aggregate_all_scenarios.csv\", index=False)\n",
        "print(f\"✓ Saved {OUTPUT_DIR}/aggregate_all_scenarios.csv\")\n",
        "\n",
        "# Print cross-scenario summary\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CROSS-SCENARIO SUMMARY (Mean ± Std across all episodes)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Group by algorithm and compute mean across scenarios\n",
        "algo_summary = aggregate_df.groupby(['algorithm', 'type']).agg({\n",
        "    'reward_mean': ['mean', 'std'],\n",
        "    'completion': 'mean',\n",
        "    'on_time_rate': 'mean',\n",
        "    'battery_used_pct': 'mean',\n",
        "}).round(2)\n",
        "\n",
        "print(algo_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVSLQr_Sbpzg",
        "outputId": "6c00f0d5-af53-4478-f359-f6fdb2b5f020"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PHASE 4: CROSS-SCENARIO AGGREGATION\n",
            "======================================================================\n",
            "✓ Saved ijcnn_results/aggregate_all_scenarios.csv\n",
            "\n",
            "======================================================================\n",
            "CROSS-SCENARIO SUMMARY (Mean ± Std across all episodes)\n",
            "======================================================================\n",
            "                             reward_mean         completion on_time_rate  \\\n",
            "                                    mean     std       mean         mean   \n",
            "algorithm           type                                                   \n",
            "Cloud-Only          Baseline     -175.82  235.97      49.56        49.56   \n",
            "Edge-Only           Baseline       -5.43  262.84      49.56        49.56   \n",
            "Latency-Greedy      Baseline     -175.82  235.97      49.56        49.56   \n",
            "Local-Only          Baseline    -6227.72  787.55      87.29        87.29   \n",
            "Multi-Metric        Baseline      174.04  167.17      73.23        73.23   \n",
            "Multi-Metric-BW     Baseline       85.63  186.49      65.08        65.08   \n",
            "Multi-Metric-Urgent Baseline      166.41  165.32      73.80        73.80   \n",
            "Random              Baseline      -23.68  180.72      67.37        67.37   \n",
            "Round-Robin         Baseline     -192.28  244.40      71.43        71.43   \n",
            "mappo               MARL          254.25  109.71      79.03        79.03   \n",
            "\n",
            "                             battery_used_pct  \n",
            "                                         mean  \n",
            "algorithm           type                       \n",
            "Cloud-Only          Baseline             0.00  \n",
            "Edge-Only           Baseline             0.00  \n",
            "Latency-Greedy      Baseline             0.00  \n",
            "Local-Only          Baseline            87.50  \n",
            "Multi-Metric        Baseline            36.61  \n",
            "Multi-Metric-BW     Baseline            23.87  \n",
            "Multi-Metric-Urgent Baseline            37.80  \n",
            "Random              Baseline            39.08  \n",
            "Round-Robin         Baseline            44.39  \n",
            "mappo               MARL                47.40  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "16CRpknWbzWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 5: FIGURE GENERATION (Updated for MAPPO vs Baselines only)\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PHASE 5: GENERATING PUBLICATION FIGURES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "figures_dir = f\"{OUTPUT_DIR}/figures\"\n",
        "Path(figures_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Algorithms to compare: baselines + MAPPO only\n",
        "algorithms_to_plot = ['Edge-Only', 'Random', 'Multi-Metric', 'MAPPO']\n",
        "colors = ['#9b59b6', '#95a5a6', '#f39c12', '#e74c3c']\n",
        "display_names = ['Edge-Only', 'Random', 'Multi-Metric', 'MAPPO (Ours)']\n",
        "\n",
        "# Prepare data\n",
        "scenarios_short = [s.replace('_', '\\n') for s in SCENARIOS]\n",
        "x = np.arange(len(SCENARIOS))\n",
        "width = 0.15\n",
        "\n",
        "# Figure 1: Cross-scenario reward comparison (grouped bar chart)\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "for i, (alg, color, display) in enumerate(zip(algorithms_to_plot, colors, display_names)):\n",
        "    means = []\n",
        "    stds = []\n",
        "    for scenario in SCENARIOS:\n",
        "        # Handle case-insensitive matching for 'mappo' vs 'MAPPO'\n",
        "        row = aggregate_df[(aggregate_df['scenario'] == scenario) &\n",
        "                          (aggregate_df['algorithm'].str.lower() == alg.lower())]\n",
        "        if len(row) > 0:\n",
        "            means.append(row['reward_mean'].values[0])\n",
        "            stds.append(row['reward_std'].values[0])\n",
        "        else:\n",
        "            means.append(0)\n",
        "            stds.append(0)\n",
        "\n",
        "    offset = (i - len(algorithms_to_plot)/2 + 0.5) * width\n",
        "    bars = ax.bar(x + offset, means, width, yerr=stds, label=display, color=color,\n",
        "                  capsize=3, alpha=0.85)\n",
        "\n",
        "ax.set_xlabel('Scenario', fontsize=12)\n",
        "ax.set_ylabel('Episode Reward', fontsize=12)\n",
        "ax.set_title('MAPPO vs Baseline Performance Across Agricultural Scenarios', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(scenarios_short)\n",
        "ax.legend(loc='upper right', ncol=2)\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{figures_dir}/cross_scenario_reward.png\", dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(f\"✓ Saved {figures_dir}/cross_scenario_reward.png\")\n",
        "\n",
        "\n",
        "# Figure 2: Completion rate comparison\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "for i, (alg, color, display) in enumerate(zip(algorithms_to_plot, colors, display_names)):\n",
        "    completions = []\n",
        "    for scenario in SCENARIOS:\n",
        "        row = aggregate_df[(aggregate_df['scenario'] == scenario) &\n",
        "                          (aggregate_df['algorithm'].str.lower() == alg.lower())]\n",
        "        if len(row) > 0:\n",
        "            completions.append(row['completion'].values[0])\n",
        "        else:\n",
        "            completions.append(0)\n",
        "\n",
        "    offset = (i - len(algorithms_to_plot)/2 + 0.5) * width\n",
        "    ax.bar(x + offset, completions, width, label=display, color=color, alpha=0.85)\n",
        "\n",
        "ax.set_xlabel('Scenario', fontsize=12)\n",
        "ax.set_ylabel('Task Completion Rate (%)', fontsize=12)\n",
        "ax.set_title('Task Completion Rate Across Scenarios', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(scenarios_short)\n",
        "ax.legend(loc='lower right', ncol=2)\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "ax.set_ylim(0, 100)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{figures_dir}/cross_scenario_completion.png\", dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(f\"✓ Saved {figures_dir}/cross_scenario_completion.png\")\n",
        "\n",
        "\n",
        "# Figure 3: Action distribution (stacked bar) - compare key policies\n",
        "fig, axes = plt.subplots(1, len(SCENARIOS), figsize=(16, 5), sharey=True)\n",
        "\n",
        "algs_for_stack = ['Edge-Only', 'Random', 'Multi-Metric', 'MAPPO']\n",
        "stack_labels = ['Edge\\nOnly', 'Random', 'Multi\\nMetric', 'MAPPO']\n",
        "\n",
        "for idx, scenario in enumerate(SCENARIOS):\n",
        "    ax = axes[idx]\n",
        "\n",
        "    local_pcts = []\n",
        "    edge_pcts = []\n",
        "    cloud_pcts = []\n",
        "\n",
        "    for alg in algs_for_stack:\n",
        "        row = aggregate_df[(aggregate_df['scenario'] == scenario) &\n",
        "                          (aggregate_df['algorithm'].str.lower() == alg.lower())]\n",
        "        if len(row) > 0:\n",
        "            local_pcts.append(row['local_pct'].values[0])\n",
        "            edge_pcts.append(row['edge_pct'].values[0])\n",
        "            cloud_pcts.append(row['cloud_pct'].values[0])\n",
        "        else:\n",
        "            local_pcts.append(0)\n",
        "            edge_pcts.append(0)\n",
        "            cloud_pcts.append(0)\n",
        "\n",
        "    x_stack = np.arange(len(algs_for_stack))\n",
        "    ax.bar(x_stack, local_pcts, label='Local' if idx == 0 else '', color='#3498db')\n",
        "    ax.bar(x_stack, edge_pcts, bottom=local_pcts, label='Edge' if idx == 0 else '', color='#2ecc71')\n",
        "    ax.bar(x_stack, cloud_pcts, bottom=np.array(local_pcts) + np.array(edge_pcts),\n",
        "           label='Cloud' if idx == 0 else '', color='#e74c3c')\n",
        "\n",
        "    ax.set_title(scenario.replace('_', ' ').title(), fontsize=11, fontweight='bold')\n",
        "    ax.set_xticks(x_stack)\n",
        "    ax.set_xticklabels(stack_labels, fontsize=8)\n",
        "    ax.set_ylim(0, 100)\n",
        "\n",
        "    if idx == 0:\n",
        "        ax.set_ylabel('Action Distribution (%)', fontsize=11)\n",
        "\n",
        "axes[0].legend(loc='upper left')\n",
        "fig.suptitle('Offloading Action Distribution by Scenario and Algorithm', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{figures_dir}/action_distribution_by_scenario.png\", dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(f\"✓ Saved {figures_dir}/action_distribution_by_scenario.png\")\n",
        "\n",
        "\n",
        "# Figure 4: MAPPO vs Multi-Metric (best heuristic baseline)\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "mappo_rewards = []\n",
        "mm_rewards = []\n",
        "\n",
        "for scenario in SCENARIOS:\n",
        "    mappo_row = aggregate_df[(aggregate_df['scenario'] == scenario) &\n",
        "                             (aggregate_df['algorithm'].str.lower() == 'mappo')]\n",
        "    mm_row = aggregate_df[(aggregate_df['scenario'] == scenario) &\n",
        "                          (aggregate_df['algorithm'] == 'Multi-Metric')]\n",
        "\n",
        "    mappo_rewards.append(mappo_row['reward_mean'].values[0] if len(mappo_row) > 0 else 0)\n",
        "    mm_rewards.append(mm_row['reward_mean'].values[0] if len(mm_row) > 0 else 0)\n",
        "\n",
        "x = np.arange(len(SCENARIOS))\n",
        "width = 0.35\n",
        "\n",
        "ax.bar(x - width/2, mappo_rewards, width, label='MAPPO (Ours)', color='#e74c3c', alpha=0.85)\n",
        "ax.bar(x + width/2, mm_rewards, width, label='Multi-Metric', color='#f39c12', alpha=0.85)\n",
        "\n",
        "ax.set_xlabel('Scenario', fontsize=12)\n",
        "ax.set_ylabel('Episode Reward', fontsize=12)\n",
        "ax.set_title('MAPPO vs Multi-Metric Baseline', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(scenarios_short)\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add improvement percentages\n",
        "# for i in range(len(SCENARIOS)):\n",
        "#     if mm_rewards[i] != 0:\n",
        "#         improvement = ((mappo_rewards[i] - mm_rewards[i]) / abs(mm_rewards[i])) * 100\n",
        "#         y_pos = max(mappo_rewards[i], mm_rewards[i]) + 10\n",
        "#         ax.annotate(f'+{improvement:.0f}%' if improvement > 0 else f'{improvement:.0f}%',\n",
        "#                    xy=(i, y_pos), ha='center', fontsize=10, fontweight='bold',\n",
        "#                    color='green' if improvement > 0 else 'red')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{figures_dir}/mappo_vs_multiMetric.png\", dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(f\"✓ Saved {figures_dir}/mappo_vs_multiMetric.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlBGE-WTbznJ",
        "outputId": "1c6444a3-3ad3-4bb3-f2e6-138e6249c882"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PHASE 5: GENERATING PUBLICATION FIGURES\n",
            "======================================================================\n",
            "✓ Saved ijcnn_results/figures/cross_scenario_reward.png\n",
            "✓ Saved ijcnn_results/figures/cross_scenario_completion.png\n",
            "✓ Saved ijcnn_results/figures/action_distribution_by_scenario.png\n",
            "✓ Saved ijcnn_results/figures/mappo_vs_multiMetric.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3Txo172Hb19i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 6: LATEX TABLE GENERATION (Updated for MAPPO vs Baselines only)\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PHASE 6: GENERATING LATEX TABLES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Algorithms to include in table: baselines + MAPPO only\n",
        "table_algorithms = ['Edge-Only', 'Random', 'Multi-Metric', 'MAPPO']\n",
        "\n",
        "latex_rows = []\n",
        "for scenario in SCENARIOS:\n",
        "    for alg in table_algorithms:\n",
        "        row = aggregate_df[(aggregate_df['scenario'] == scenario) &\n",
        "                          (aggregate_df['algorithm'].str.lower() == alg.lower())]\n",
        "        if len(row) > 0:\n",
        "            r = row.iloc[0]\n",
        "            latex_rows.append({\n",
        "                'Scenario': scenario.replace('_', ' ').title(),\n",
        "                'Algorithm': alg if alg != 'MAPPO' else '\\\\textbf{MAPPO (Ours)}',\n",
        "                'Reward': f\"{r['reward_mean']:.1f} $\\\\pm$ {r['reward_std']:.1f}\",\n",
        "                'Completion': f\"{r['completion']:.1f}\\\\%\",\n",
        "                'On-Time': f\"{r['on_time_rate']:.1f}\\\\%\",\n",
        "                'Battery': f\"{r['battery_used_pct']:.1f}\\\\%\",\n",
        "                'Actions (L/E/C)': f\"{r['local_pct']:.0f}/{r['edge_pct']:.0f}/{r['cloud_pct']:.0f}\",\n",
        "            })\n",
        "\n",
        "latex_df = pd.DataFrame(latex_rows)\n",
        "latex_df.to_csv(f\"{OUTPUT_DIR}/latex_table_data.csv\", index=False)\n",
        "\n",
        "# Generate LaTeX table\n",
        "latex_str = r\"\"\"\n",
        "\\begin{table*}[htbp]\n",
        "\\centering\n",
        "\\caption{Performance comparison of MAPPO against baseline strategies across agricultural scenarios.\n",
        "Reward is mean $\\pm$ std over evaluation episodes. Completion and On-Time rates indicate\n",
        "percentage of tasks completed and completed before deadline, respectively.\n",
        "Actions show distribution across Local/Edge/Cloud execution.}\n",
        "\\label{tab:cross_scenario_results}\n",
        "\\resizebox{\\textwidth}{!}{\n",
        "\\begin{tabular}{llccccc}\n",
        "\\toprule\n",
        "\\textbf{Scenario} & \\textbf{Algorithm} & \\textbf{Reward} & \\textbf{Completion} & \\textbf{On-Time} & \\textbf{Battery Used} & \\textbf{Actions (L/E/C)} \\\\\n",
        "\\midrule\n",
        "\"\"\"\n",
        "\n",
        "current_scenario = None\n",
        "for _, row in latex_df.iterrows():\n",
        "    if row['Scenario'] != current_scenario:\n",
        "        if current_scenario is not None:\n",
        "            latex_str += r\"\\midrule\" + \"\\n\"\n",
        "        current_scenario = row['Scenario']\n",
        "\n",
        "    # Bold the best reward in each scenario\n",
        "    latex_str += f\"{row['Scenario']} & {row['Algorithm']} & {row['Reward']} & {row['Completion']} & {row['On-Time']} & {row['Battery']} & {row['Actions (L/E/C)']} \\\\\\\\\\n\"\n",
        "\n",
        "latex_str += r\"\"\"\n",
        "\\bottomrule\n",
        "\\end{tabular}\n",
        "}\n",
        "\\end{table*}\n",
        "\"\"\"\n",
        "\n",
        "with open(f\"{OUTPUT_DIR}/results_table.tex\", 'w') as f:\n",
        "    f.write(latex_str)\n",
        "print(f\"✓ Saved {OUTPUT_DIR}/results_table.tex\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# FINAL SUMMARY\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"EXPERIMENT COMPLETE - FINAL SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Filter to only the algorithms we care about\n",
        "summary_algs = ['Local-Only', 'Edge-Only', 'Random', 'Multi-Metric', 'MAPPO']\n",
        "filtered_df = aggregate_df[aggregate_df['algorithm'].str.lower().isin([a.lower() for a in summary_algs])]\n",
        "\n",
        "print(\"\\n📊 Overall Results (averaged across all scenarios):\\n\")\n",
        "\n",
        "overall_summary = filtered_df.groupby('algorithm').agg({\n",
        "    'reward_mean': 'mean',\n",
        "    'completion': 'mean',\n",
        "    'on_time_rate': 'mean',\n",
        "}).sort_values('reward_mean', ascending=False)\n",
        "\n",
        "print(overall_summary.round(2).to_string())\n",
        "\n",
        "best_alg = overall_summary.index[0]\n",
        "best_reward = overall_summary.loc[best_alg, 'reward_mean']\n",
        "print(f\"\\n🏆 Best Overall Algorithm: {best_alg} (mean reward: {best_reward:.1f})\")\n",
        "\n",
        "# Compute improvement over baselines\n",
        "if 'Multi-Metric' in overall_summary.index and best_alg.lower() == 'mappo':\n",
        "    mm_reward = overall_summary.loc['Multi-Metric', 'reward_mean']\n",
        "    improvement = ((best_reward - mm_reward) / abs(mm_reward)) * 100 if mm_reward != 0 else 0\n",
        "    print(f\"📈 Improvement over Multi-Metric: {improvement:+.1f}%\")\n",
        "\n",
        "# Print file listing\n",
        "print(f\"\\n📁 Output files in {OUTPUT_DIR}/:\")\n",
        "for root, dirs, files in os.walk(OUTPUT_DIR):\n",
        "    level = root.replace(OUTPUT_DIR, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f'{indent}{os.path.basename(root)}/')\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files[:5]:\n",
        "        print(f'{subindent}{file}')\n",
        "    if len(files) > 5:\n",
        "        print(f'{subindent}... and {len(files) - 5} more files')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8InlowqCb2MO",
        "outputId": "334fc208-0ebb-46f7-dcc4-16cd6b625631"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "PHASE 6: GENERATING LATEX TABLES\n",
            "======================================================================\n",
            "✓ Saved ijcnn_results/results_table.tex\n",
            "\n",
            "======================================================================\n",
            "EXPERIMENT COMPLETE - FINAL SUMMARY\n",
            "======================================================================\n",
            "\n",
            "📊 Overall Results (averaged across all scenarios):\n",
            "\n",
            "              reward_mean  completion  on_time_rate\n",
            "algorithm                                          \n",
            "mappo              254.25       79.03         79.03\n",
            "Multi-Metric       174.04       73.23         73.23\n",
            "Edge-Only           -5.43       49.56         49.56\n",
            "Random             -23.68       67.37         67.37\n",
            "Local-Only       -6227.72       87.29         87.29\n",
            "\n",
            "🏆 Best Overall Algorithm: mappo (mean reward: 254.2)\n",
            "📈 Improvement over Multi-Metric: +46.1%\n",
            "\n",
            "📁 Output files in ijcnn_results/:\n",
            "ijcnn_results/\n",
            "  results_table.tex\n",
            "  latex_table_data.csv\n",
            "  aggregate_all_scenarios.csv\n",
            "  network_aware/\n",
            "    config.json\n",
            "    summary_table.tex\n",
            "    aggregate_metrics.csv\n",
            "    summary_table.csv\n",
            "    marl/\n",
            "      mappo/\n",
            "        episode_metrics.csv\n",
            "        summary.json\n",
            "    baselines/\n",
            "      Cloud_Only/\n",
            "        episode_metrics.csv\n",
            "      Random/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_BW/\n",
            "        episode_metrics.csv\n",
            "      Latency_Greedy/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_Urgent/\n",
            "        episode_metrics.csv\n",
            "      Local_Only/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric/\n",
            "        episode_metrics.csv\n",
            "      Edge_Only/\n",
            "        episode_metrics.csv\n",
            "      Round_Robin/\n",
            "        episode_metrics.csv\n",
            "    figures/\n",
            "      ontime_comparison.png\n",
            "      reward_comparison.png\n",
            "      battery_comparison.png\n",
            "      completion_comparison.png\n",
            "      action_distribution.png\n",
            "      ... and 2 more files\n",
            "  variable_terrain/\n",
            "    config.json\n",
            "    summary_table.tex\n",
            "    aggregate_metrics.csv\n",
            "    summary_table.csv\n",
            "    marl/\n",
            "      mappo/\n",
            "        episode_metrics.csv\n",
            "        summary.json\n",
            "    baselines/\n",
            "      Cloud_Only/\n",
            "        episode_metrics.csv\n",
            "      Random/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_BW/\n",
            "        episode_metrics.csv\n",
            "      Latency_Greedy/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_Urgent/\n",
            "        episode_metrics.csv\n",
            "      Local_Only/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric/\n",
            "        episode_metrics.csv\n",
            "      Edge_Only/\n",
            "        episode_metrics.csv\n",
            "      Round_Robin/\n",
            "        episode_metrics.csv\n",
            "    figures/\n",
            "      ontime_comparison.png\n",
            "      reward_comparison.png\n",
            "      battery_comparison.png\n",
            "      completion_comparison.png\n",
            "      action_distribution.png\n",
            "      ... and 2 more files\n",
            "  streaming_hard/\n",
            "    config.json\n",
            "    summary_table.tex\n",
            "    aggregate_metrics.csv\n",
            "    summary_table.csv\n",
            "    marl/\n",
            "      mappo/\n",
            "        episode_metrics.csv\n",
            "        summary.json\n",
            "    baselines/\n",
            "      Cloud_Only/\n",
            "        episode_metrics.csv\n",
            "      Random/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_BW/\n",
            "        episode_metrics.csv\n",
            "      Latency_Greedy/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_Urgent/\n",
            "        episode_metrics.csv\n",
            "      Local_Only/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric/\n",
            "        episode_metrics.csv\n",
            "      Edge_Only/\n",
            "        episode_metrics.csv\n",
            "      Round_Robin/\n",
            "        episode_metrics.csv\n",
            "    figures/\n",
            "      ontime_comparison.png\n",
            "      reward_comparison.png\n",
            "      battery_comparison.png\n",
            "      completion_comparison.png\n",
            "      action_distribution.png\n",
            "      ... and 2 more files\n",
            "  models/\n",
            "    network_aware/\n",
            "      mappo/\n",
            "        seed_2/\n",
            "        seed_1/\n",
            "        seed_0/\n",
            "    variable_terrain/\n",
            "      mappo/\n",
            "        seed_2/\n",
            "        seed_1/\n",
            "        seed_0/\n",
            "    streaming_hard/\n",
            "      mappo/\n",
            "        seed_2/\n",
            "        seed_1/\n",
            "        seed_0/\n",
            "    rural_field/\n",
            "      mappo/\n",
            "        seed_2/\n",
            "        seed_1/\n",
            "        seed_0/\n",
            "  rural_field/\n",
            "    config.json\n",
            "    summary_table.tex\n",
            "    aggregate_metrics.csv\n",
            "    summary_table.csv\n",
            "    marl/\n",
            "      mappo/\n",
            "        episode_metrics.csv\n",
            "        summary.json\n",
            "    baselines/\n",
            "      Cloud_Only/\n",
            "        episode_metrics.csv\n",
            "      Random/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_BW/\n",
            "        episode_metrics.csv\n",
            "      Latency_Greedy/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_Urgent/\n",
            "        episode_metrics.csv\n",
            "      Local_Only/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric/\n",
            "        episode_metrics.csv\n",
            "      Edge_Only/\n",
            "        episode_metrics.csv\n",
            "      Round_Robin/\n",
            "        episode_metrics.csv\n",
            "    figures/\n",
            "      ontime_comparison.png\n",
            "      reward_comparison.png\n",
            "      battery_comparison.png\n",
            "      completion_comparison.png\n",
            "      action_distribution.png\n",
            "      ... and 2 more files\n",
            "  figures/\n",
            "    mappo_vs_multiMetric.png\n",
            "    cross_scenario_reward.png\n",
            "    action_distribution_by_scenario.png\n",
            "    cross_scenario_completion.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-RHzy1ysb4JX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"EXPERIMENT COMPLETE - FINAL SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Overall best performer\n",
        "print(\"\\n📊 Overall Results (averaged across all scenarios):\\n\")\n",
        "\n",
        "overall_summary = aggregate_df.groupby('algorithm').agg({\n",
        "    'reward_mean': 'mean',\n",
        "    'completion': 'mean',\n",
        "    'on_time_rate': 'mean',\n",
        "}).sort_values('reward_mean', ascending=False)\n",
        "\n",
        "print(overall_summary.round(2).to_string())\n",
        "\n",
        "best_alg = overall_summary.index[0]\n",
        "best_reward = overall_summary.loc[best_alg, 'reward_mean']\n",
        "print(f\"\\n🏆 Best Overall Algorithm: {best_alg} (mean reward: {best_reward:.1f})\")\n",
        "\n",
        "# Print file listing\n",
        "print(f\"\\n📁 Output files in {OUTPUT_DIR}/:\")\n",
        "for root, dirs, files in os.walk(OUTPUT_DIR):\n",
        "    level = root.replace(OUTPUT_DIR, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f'{indent}{os.path.basename(root)}/')\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files[:5]:  # Limit to first 5 files per dir\n",
        "        print(f'{subindent}{file}')\n",
        "    if len(files) > 5:\n",
        "        print(f'{subindent}... and {len(files) - 5} more files')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLn4WUm6b4Zh",
        "outputId": "d8a1f239-bbd2-49e9-ca94-cfe468f398cf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "EXPERIMENT COMPLETE - FINAL SUMMARY\n",
            "======================================================================\n",
            "\n",
            "📊 Overall Results (averaged across all scenarios):\n",
            "\n",
            "                     reward_mean  completion  on_time_rate\n",
            "algorithm                                                 \n",
            "mappo                     254.25       79.03         79.03\n",
            "Multi-Metric              174.04       73.23         73.23\n",
            "Multi-Metric-Urgent       166.41       73.80         73.80\n",
            "Multi-Metric-BW            85.63       65.08         65.08\n",
            "Edge-Only                  -5.43       49.56         49.56\n",
            "Random                    -23.68       67.37         67.37\n",
            "Cloud-Only               -175.82       49.56         49.56\n",
            "Latency-Greedy           -175.82       49.56         49.56\n",
            "Round-Robin              -192.28       71.43         71.43\n",
            "Local-Only              -6227.72       87.29         87.29\n",
            "\n",
            "🏆 Best Overall Algorithm: mappo (mean reward: 254.2)\n",
            "\n",
            "📁 Output files in ijcnn_results/:\n",
            "ijcnn_results/\n",
            "  results_table.tex\n",
            "  latex_table_data.csv\n",
            "  aggregate_all_scenarios.csv\n",
            "  network_aware/\n",
            "    config.json\n",
            "    summary_table.tex\n",
            "    aggregate_metrics.csv\n",
            "    summary_table.csv\n",
            "    marl/\n",
            "      mappo/\n",
            "        episode_metrics.csv\n",
            "        summary.json\n",
            "    baselines/\n",
            "      Cloud_Only/\n",
            "        episode_metrics.csv\n",
            "      Random/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_BW/\n",
            "        episode_metrics.csv\n",
            "      Latency_Greedy/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_Urgent/\n",
            "        episode_metrics.csv\n",
            "      Local_Only/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric/\n",
            "        episode_metrics.csv\n",
            "      Edge_Only/\n",
            "        episode_metrics.csv\n",
            "      Round_Robin/\n",
            "        episode_metrics.csv\n",
            "    figures/\n",
            "      ontime_comparison.png\n",
            "      reward_comparison.png\n",
            "      battery_comparison.png\n",
            "      completion_comparison.png\n",
            "      action_distribution.png\n",
            "      ... and 2 more files\n",
            "  variable_terrain/\n",
            "    config.json\n",
            "    summary_table.tex\n",
            "    aggregate_metrics.csv\n",
            "    summary_table.csv\n",
            "    marl/\n",
            "      mappo/\n",
            "        episode_metrics.csv\n",
            "        summary.json\n",
            "    baselines/\n",
            "      Cloud_Only/\n",
            "        episode_metrics.csv\n",
            "      Random/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_BW/\n",
            "        episode_metrics.csv\n",
            "      Latency_Greedy/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_Urgent/\n",
            "        episode_metrics.csv\n",
            "      Local_Only/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric/\n",
            "        episode_metrics.csv\n",
            "      Edge_Only/\n",
            "        episode_metrics.csv\n",
            "      Round_Robin/\n",
            "        episode_metrics.csv\n",
            "    figures/\n",
            "      ontime_comparison.png\n",
            "      reward_comparison.png\n",
            "      battery_comparison.png\n",
            "      completion_comparison.png\n",
            "      action_distribution.png\n",
            "      ... and 2 more files\n",
            "  streaming_hard/\n",
            "    config.json\n",
            "    summary_table.tex\n",
            "    aggregate_metrics.csv\n",
            "    summary_table.csv\n",
            "    marl/\n",
            "      mappo/\n",
            "        episode_metrics.csv\n",
            "        summary.json\n",
            "    baselines/\n",
            "      Cloud_Only/\n",
            "        episode_metrics.csv\n",
            "      Random/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_BW/\n",
            "        episode_metrics.csv\n",
            "      Latency_Greedy/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_Urgent/\n",
            "        episode_metrics.csv\n",
            "      Local_Only/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric/\n",
            "        episode_metrics.csv\n",
            "      Edge_Only/\n",
            "        episode_metrics.csv\n",
            "      Round_Robin/\n",
            "        episode_metrics.csv\n",
            "    figures/\n",
            "      ontime_comparison.png\n",
            "      reward_comparison.png\n",
            "      battery_comparison.png\n",
            "      completion_comparison.png\n",
            "      action_distribution.png\n",
            "      ... and 2 more files\n",
            "  models/\n",
            "    network_aware/\n",
            "      mappo/\n",
            "        seed_2/\n",
            "        seed_1/\n",
            "        seed_0/\n",
            "    variable_terrain/\n",
            "      mappo/\n",
            "        seed_2/\n",
            "        seed_1/\n",
            "        seed_0/\n",
            "    streaming_hard/\n",
            "      mappo/\n",
            "        seed_2/\n",
            "        seed_1/\n",
            "        seed_0/\n",
            "    rural_field/\n",
            "      mappo/\n",
            "        seed_2/\n",
            "        seed_1/\n",
            "        seed_0/\n",
            "  rural_field/\n",
            "    config.json\n",
            "    summary_table.tex\n",
            "    aggregate_metrics.csv\n",
            "    summary_table.csv\n",
            "    marl/\n",
            "      mappo/\n",
            "        episode_metrics.csv\n",
            "        summary.json\n",
            "    baselines/\n",
            "      Cloud_Only/\n",
            "        episode_metrics.csv\n",
            "      Random/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_BW/\n",
            "        episode_metrics.csv\n",
            "      Latency_Greedy/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric_Urgent/\n",
            "        episode_metrics.csv\n",
            "      Local_Only/\n",
            "        episode_metrics.csv\n",
            "      Multi_Metric/\n",
            "        episode_metrics.csv\n",
            "      Edge_Only/\n",
            "        episode_metrics.csv\n",
            "      Round_Robin/\n",
            "        episode_metrics.csv\n",
            "    figures/\n",
            "      ontime_comparison.png\n",
            "      reward_comparison.png\n",
            "      battery_comparison.png\n",
            "      completion_comparison.png\n",
            "      action_distribution.png\n",
            "      ... and 2 more files\n",
            "  figures/\n",
            "    mappo_vs_multiMetric.png\n",
            "    cross_scenario_reward.png\n",
            "    action_distribution_by_scenario.png\n",
            "    cross_scenario_completion.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TRplHMYCb9tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r {OUTPUT_DIR}.zip {OUTPUT_DIR}/\n",
        "from google.colab import files\n",
        "files.download(f'{OUTPUT_DIR}.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DKjk4raWb-cA",
        "outputId": "6e58a45e-9916-43ef-9f01-6e58d9ef214f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: ijcnn_results/ (stored 0%)\n",
            "updating: ijcnn_results/network_aware/ (stored 0%)\n",
            "updating: ijcnn_results/network_aware/marl/ (stored 0%)\n",
            "updating: ijcnn_results/network_aware/marl/mappo/ (stored 0%)\n",
            "updating: ijcnn_results/network_aware/marl/mappo/episode_metrics.csv (deflated 70%)\n",
            "updating: ijcnn_results/network_aware/marl/mappo/summary.json (deflated 54%)\n",
            "updating: ijcnn_results/network_aware/config.json (deflated 18%)\n",
            "updating: ijcnn_results/network_aware/baselines/ (stored 0%)\n",
            "updating: ijcnn_results/network_aware/baselines/Cloud_Only/ (stored 0%)\n",
            "updating: ijcnn_results/network_aware/baselines/Cloud_Only/episode_metrics.csv (deflated 72%)\n",
            "updating: ijcnn_results/network_aware/baselines/Random/ (stored 0%)\n",
            "updating: ijcnn_results/network_aware/baselines/Random/episode_metrics.csv (deflated 67%)\n",
            "updating: ijcnn_results/network_aware/baselines/Multi_Metric_BW/ (stored 0%)\n",
            "updating: ijcnn_results/network_aware/baselines/Multi_Metric_BW/episode_metrics.csv (deflated 69%)\n",
            "updating: ijcnn_results/network_aware/baselines/Latency_Greedy/ (stored 0%)\n",
            "updating: ijcnn_results/network_aware/baselines/Latency_Greedy/episode_metrics.csv (deflated 72%)\n",
            "updating: ijcnn_results/network_aware/baselines/Multi_Metric_Urgent/ (stored 0%)\n",
            "updating: ijcnn_results/network_aware/baselines/Multi_Metric_Urgent/episode_metrics.csv (deflated 71%)\n",
            "updating: ijcnn_results/network_aware/baselines/Local_Only/ (stored 0%)\n",
            "updating: ijcnn_results/network_aware/baselines/Local_Only/episode_metrics.csv (deflated 88%)\n",
            "updating: ijcnn_results/network_aware/baselines/Multi_Metric/ (stored 0%)\n",
            "updating: ijcnn_results/network_aware/baselines/Multi_Metric/episode_metrics.csv (deflated 69%)\n",
            "updating: ijcnn_results/network_aware/baselines/Edge_Only/ (stored 0%)\n",
            "updating: ijcnn_results/network_aware/baselines/Edge_Only/episode_metrics.csv (deflated 73%)\n",
            "updating: ijcnn_results/network_aware/baselines/Round_Robin/ (stored 0%)\n",
            "updating: ijcnn_results/network_aware/baselines/Round_Robin/episode_metrics.csv (deflated 74%)\n",
            "updating: ijcnn_results/network_aware/summary_table.tex (deflated 50%)\n",
            "updating: ijcnn_results/network_aware/aggregate_metrics.csv (deflated 43%)\n",
            "updating: ijcnn_results/network_aware/figures/ (stored 0%)\n",
            "updating: ijcnn_results/network_aware/figures/ontime_comparison.png (deflated 17%)\n",
            "updating: ijcnn_results/network_aware/figures/reward_comparison.png (deflated 18%)\n",
            "updating: ijcnn_results/network_aware/figures/battery_comparison.png (deflated 17%)\n",
            "updating: ijcnn_results/network_aware/figures/completion_comparison.png (deflated 17%)\n",
            "updating: ijcnn_results/network_aware/figures/action_distribution.png (deflated 15%)\n",
            "updating: ijcnn_results/network_aware/figures/multi_metric_comparison.png (deflated 19%)\n",
            "updating: ijcnn_results/network_aware/figures/latency_comparison.png (deflated 17%)\n",
            "updating: ijcnn_results/network_aware/summary_table.csv (deflated 51%)\n",
            "updating: ijcnn_results/variable_terrain/ (stored 0%)\n",
            "updating: ijcnn_results/variable_terrain/marl/ (stored 0%)\n",
            "updating: ijcnn_results/variable_terrain/marl/mappo/ (stored 0%)\n",
            "updating: ijcnn_results/variable_terrain/marl/mappo/episode_metrics.csv (deflated 71%)\n",
            "updating: ijcnn_results/variable_terrain/marl/mappo/summary.json (deflated 54%)\n",
            "updating: ijcnn_results/variable_terrain/config.json (deflated 19%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/ (stored 0%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Cloud_Only/ (stored 0%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Cloud_Only/episode_metrics.csv (deflated 73%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Random/ (stored 0%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Random/episode_metrics.csv (deflated 70%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Multi_Metric_BW/ (stored 0%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Multi_Metric_BW/episode_metrics.csv (deflated 71%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Latency_Greedy/ (stored 0%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Latency_Greedy/episode_metrics.csv (deflated 73%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Multi_Metric_Urgent/ (stored 0%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Multi_Metric_Urgent/episode_metrics.csv (deflated 72%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Local_Only/ (stored 0%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Local_Only/episode_metrics.csv (deflated 86%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Multi_Metric/ (stored 0%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Multi_Metric/episode_metrics.csv (deflated 71%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Edge_Only/ (stored 0%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Edge_Only/episode_metrics.csv (deflated 73%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Round_Robin/ (stored 0%)\n",
            "updating: ijcnn_results/variable_terrain/baselines/Round_Robin/episode_metrics.csv (deflated 74%)\n",
            "updating: ijcnn_results/variable_terrain/summary_table.tex (deflated 50%)\n",
            "updating: ijcnn_results/variable_terrain/aggregate_metrics.csv (deflated 44%)\n",
            "updating: ijcnn_results/variable_terrain/figures/ (stored 0%)\n",
            "updating: ijcnn_results/variable_terrain/figures/ontime_comparison.png (deflated 17%)\n",
            "updating: ijcnn_results/variable_terrain/figures/reward_comparison.png (deflated 17%)\n",
            "updating: ijcnn_results/variable_terrain/figures/battery_comparison.png (deflated 17%)\n",
            "updating: ijcnn_results/variable_terrain/figures/completion_comparison.png (deflated 17%)\n",
            "updating: ijcnn_results/variable_terrain/figures/action_distribution.png (deflated 15%)\n",
            "updating: ijcnn_results/variable_terrain/figures/multi_metric_comparison.png (deflated 19%)\n",
            "updating: ijcnn_results/variable_terrain/figures/latency_comparison.png (deflated 16%)\n",
            "updating: ijcnn_results/variable_terrain/summary_table.csv (deflated 50%)\n",
            "updating: ijcnn_results/streaming_hard/ (stored 0%)\n",
            "updating: ijcnn_results/streaming_hard/marl/ (stored 0%)\n",
            "updating: ijcnn_results/streaming_hard/marl/mappo/ (stored 0%)\n",
            "updating: ijcnn_results/streaming_hard/marl/mappo/episode_metrics.csv (deflated 70%)\n",
            "updating: ijcnn_results/streaming_hard/marl/mappo/summary.json (deflated 62%)\n",
            "updating: ijcnn_results/streaming_hard/config.json (deflated 18%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/ (stored 0%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Cloud_Only/ (stored 0%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Cloud_Only/episode_metrics.csv (deflated 71%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Random/ (stored 0%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Random/episode_metrics.csv (deflated 71%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Multi_Metric_BW/ (stored 0%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Multi_Metric_BW/episode_metrics.csv (deflated 71%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Latency_Greedy/ (stored 0%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Latency_Greedy/episode_metrics.csv (deflated 71%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Multi_Metric_Urgent/ (stored 0%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Multi_Metric_Urgent/episode_metrics.csv (deflated 75%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Local_Only/ (stored 0%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Local_Only/episode_metrics.csv (deflated 88%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Multi_Metric/ (stored 0%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Multi_Metric/episode_metrics.csv (deflated 71%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Edge_Only/ (stored 0%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Edge_Only/episode_metrics.csv (deflated 71%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Round_Robin/ (stored 0%)\n",
            "updating: ijcnn_results/streaming_hard/baselines/Round_Robin/episode_metrics.csv (deflated 77%)\n",
            "updating: ijcnn_results/streaming_hard/summary_table.tex (deflated 50%)\n",
            "updating: ijcnn_results/streaming_hard/aggregate_metrics.csv (deflated 44%)\n",
            "updating: ijcnn_results/streaming_hard/figures/ (stored 0%)\n",
            "updating: ijcnn_results/streaming_hard/figures/ontime_comparison.png (deflated 17%)\n",
            "updating: ijcnn_results/streaming_hard/figures/reward_comparison.png (deflated 18%)\n",
            "updating: ijcnn_results/streaming_hard/figures/battery_comparison.png (deflated 17%)\n",
            "updating: ijcnn_results/streaming_hard/figures/completion_comparison.png (deflated 17%)\n",
            "updating: ijcnn_results/streaming_hard/figures/action_distribution.png (deflated 15%)\n",
            "updating: ijcnn_results/streaming_hard/figures/multi_metric_comparison.png (deflated 19%)\n",
            "updating: ijcnn_results/streaming_hard/figures/latency_comparison.png (deflated 18%)\n",
            "updating: ijcnn_results/streaming_hard/summary_table.csv (deflated 50%)\n",
            "updating: ijcnn_results/models/ (stored 0%)\n",
            "updating: ijcnn_results/models/network_aware/ (stored 0%)\n",
            "updating: ijcnn_results/models/network_aware/mappo/ (stored 0%)\n",
            "updating: ijcnn_results/models/network_aware/mappo/seed_2/ (stored 0%)\n",
            "updating: ijcnn_results/models/network_aware/mappo/seed_1/ (stored 0%)\n",
            "updating: ijcnn_results/models/network_aware/mappo/seed_0/ (stored 0%)\n",
            "updating: ijcnn_results/models/variable_terrain/ (stored 0%)\n",
            "updating: ijcnn_results/models/variable_terrain/mappo/ (stored 0%)\n",
            "updating: ijcnn_results/models/variable_terrain/mappo/seed_2/ (stored 0%)\n",
            "updating: ijcnn_results/models/variable_terrain/mappo/seed_1/ (stored 0%)\n",
            "updating: ijcnn_results/models/variable_terrain/mappo/seed_0/ (stored 0%)\n",
            "updating: ijcnn_results/models/streaming_hard/ (stored 0%)\n",
            "updating: ijcnn_results/models/streaming_hard/mappo/ (stored 0%)\n",
            "updating: ijcnn_results/models/streaming_hard/mappo/seed_2/ (stored 0%)\n",
            "updating: ijcnn_results/models/streaming_hard/mappo/seed_1/ (stored 0%)\n",
            "updating: ijcnn_results/models/streaming_hard/mappo/seed_0/ (stored 0%)\n",
            "updating: ijcnn_results/models/rural_field/ (stored 0%)\n",
            "updating: ijcnn_results/models/rural_field/mappo/ (stored 0%)\n",
            "updating: ijcnn_results/models/rural_field/mappo/seed_2/ (stored 0%)\n",
            "updating: ijcnn_results/models/rural_field/mappo/seed_1/ (stored 0%)\n",
            "updating: ijcnn_results/models/rural_field/mappo/seed_0/ (stored 0%)\n",
            "updating: ijcnn_results/results_table.tex (deflated 59%)\n",
            "updating: ijcnn_results/latex_table_data.csv (deflated 58%)\n",
            "updating: ijcnn_results/rural_field/ (stored 0%)\n",
            "updating: ijcnn_results/rural_field/marl/ (stored 0%)\n",
            "updating: ijcnn_results/rural_field/marl/mappo/ (stored 0%)\n",
            "updating: ijcnn_results/rural_field/marl/mappo/episode_metrics.csv (deflated 63%)\n",
            "updating: ijcnn_results/rural_field/marl/mappo/summary.json (deflated 60%)\n",
            "updating: ijcnn_results/rural_field/config.json (deflated 19%)\n",
            "updating: ijcnn_results/rural_field/baselines/ (stored 0%)\n",
            "updating: ijcnn_results/rural_field/baselines/Cloud_Only/ (stored 0%)\n",
            "updating: ijcnn_results/rural_field/baselines/Cloud_Only/episode_metrics.csv (deflated 69%)\n",
            "updating: ijcnn_results/rural_field/baselines/Random/ (stored 0%)\n",
            "updating: ijcnn_results/rural_field/baselines/Random/episode_metrics.csv (deflated 66%)\n",
            "updating: ijcnn_results/rural_field/baselines/Multi_Metric_BW/ (stored 0%)\n",
            "updating: ijcnn_results/rural_field/baselines/Multi_Metric_BW/episode_metrics.csv (deflated 67%)\n",
            "updating: ijcnn_results/rural_field/baselines/Latency_Greedy/ (stored 0%)\n",
            "updating: ijcnn_results/rural_field/baselines/Latency_Greedy/episode_metrics.csv (deflated 69%)\n",
            "updating: ijcnn_results/rural_field/baselines/Multi_Metric_Urgent/ (stored 0%)\n",
            "updating: ijcnn_results/rural_field/baselines/Multi_Metric_Urgent/episode_metrics.csv (deflated 73%)\n",
            "updating: ijcnn_results/rural_field/baselines/Local_Only/ (stored 0%)\n",
            "updating: ijcnn_results/rural_field/baselines/Local_Only/episode_metrics.csv (deflated 85%)\n",
            "updating: ijcnn_results/rural_field/baselines/Multi_Metric/ (stored 0%)\n",
            "updating: ijcnn_results/rural_field/baselines/Multi_Metric/episode_metrics.csv (deflated 70%)\n",
            "updating: ijcnn_results/rural_field/baselines/Edge_Only/ (stored 0%)\n",
            "updating: ijcnn_results/rural_field/baselines/Edge_Only/episode_metrics.csv (deflated 69%)\n",
            "updating: ijcnn_results/rural_field/baselines/Round_Robin/ (stored 0%)\n",
            "updating: ijcnn_results/rural_field/baselines/Round_Robin/episode_metrics.csv (deflated 76%)\n",
            "updating: ijcnn_results/rural_field/summary_table.tex (deflated 50%)\n",
            "updating: ijcnn_results/rural_field/aggregate_metrics.csv (deflated 41%)\n",
            "updating: ijcnn_results/rural_field/figures/ (stored 0%)\n",
            "updating: ijcnn_results/rural_field/figures/ontime_comparison.png (deflated 17%)\n",
            "updating: ijcnn_results/rural_field/figures/reward_comparison.png (deflated 17%)\n",
            "updating: ijcnn_results/rural_field/figures/battery_comparison.png (deflated 17%)\n",
            "updating: ijcnn_results/rural_field/figures/completion_comparison.png (deflated 17%)\n",
            "updating: ijcnn_results/rural_field/figures/action_distribution.png (deflated 16%)\n",
            "updating: ijcnn_results/rural_field/figures/multi_metric_comparison.png (deflated 19%)\n",
            "updating: ijcnn_results/rural_field/figures/latency_comparison.png (deflated 16%)\n",
            "updating: ijcnn_results/rural_field/summary_table.csv (deflated 50%)\n",
            "updating: ijcnn_results/figures/ (stored 0%)\n",
            "updating: ijcnn_results/figures/mappo_vs_multiMetric.png (deflated 25%)\n",
            "updating: ijcnn_results/figures/cross_scenario_reward.png (deflated 21%)\n",
            "updating: ijcnn_results/figures/action_distribution_by_scenario.png (deflated 21%)\n",
            "updating: ijcnn_results/figures/cross_scenario_completion.png (deflated 22%)\n",
            "updating: ijcnn_results/aggregate_all_scenarios.csv (deflated 65%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2b8103d5-2a5c-4d39-8b4a-e4e279494f77\", \"ijcnn_results.zip\", 2242475)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i5HVbLhQlFXx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}